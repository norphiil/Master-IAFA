{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tz9j5EYN-73m"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.distributions.beta import Beta\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MixUpModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Module MixUp that mixes batch and labels with a parameter lambda sampled from a beta distribution.\n",
        "    Code overview :\n",
        "    >>> lambda ~ Beta(alpha, alpha)\n",
        "    >>> lambda = max(lambda, 1 - lambda)\n",
        "    >>> batch = batch_a * lambda + batch_b * (1 - lambda)\n",
        "    >>> label = label_a * lambda + label_b * (1 - lambda)\n",
        "    Notes:\n",
        "            - if alpha -> 0 and apply_max == True, lambda sampled near 1,\n",
        "            - if alpha -> 1 and apply_max == True, lambda sampled from an uniform distribution in [0.5, 1.0],\n",
        "            - if alpha -> 0 and apply_max == False, lambda sampled near 1 or 0,\n",
        "            - if alpha -> 1 and apply_max == False, lambda sampled from an uniform distribution in [0.0, 1.0],\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sample_lambda: bool = True, _lambda: float = 0.5, alpha: float = 0.4, apply_max: bool = False) -> None:\n",
        "        \"\"\"\n",
        "        Build the MixUp Module.\n",
        "        :param alpha: Controls the Beta distribution used to sample the lambda coefficient. (default: 0.4)\n",
        "        :param apply_max: If True, apply the 'lambda = max(lambda, 1 - lambda)' after the sampling of lambda. (default: False)\n",
        "                This operation is useful for having a mixed batch close to the first batch passed as input.\n",
        "                It was set to True in MixMatch training but not in original MixUp training.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.apply_max = apply_max\n",
        "\n",
        "        self.sample_lambda = sample_lambda\n",
        "        if self.sample_lambda:\n",
        "            self._beta = Beta(alpha, alpha)\n",
        "        self._lambda = _lambda\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        xa: Tensor,\n",
        "        xb: Tensor,\n",
        "        ya: Tensor,\n",
        "        yb: Tensor,\n",
        "    ) -> Tuple[Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Apply MixUp to batches and labels.\n",
        "        \"\"\"\n",
        "        if xa.shape != xb.shape or ya.shape != yb.shape:\n",
        "            raise RuntimeError(\n",
        "                \"Invalid shapes for MixUp : ({} != {} or {} != {})\".format(\n",
        "                    xa.shape, xb.shape, ya.shape, yb.shape\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Sample from Beta distribution\n",
        "        if self.sample_lambda:\n",
        "            self._lambda = self._beta.sample().item() if self.alpha > 0.0 else 1.0\n",
        "\n",
        "        if self.apply_max:\n",
        "            self._lambda = max(self._lambda, 1.0 - self._lambda)\n",
        "\n",
        "        batch_mix = ??\n",
        "        labels_mix = ??\n",
        "\n",
        "        return batch_mix, labels_mix\n",
        "\n",
        "    def get_last_lambda(self) -> float:\n",
        "        \"\"\"\n",
        "        :returns: the last lambda sampled. If no data has been passed to forward(), returns 0.0.\n",
        "        \"\"\"\n",
        "        return self._lambda"
      ],
      "metadata": {
        "id": "uca38MGr_Fhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement de CIFAR10"
      ],
      "metadata": {
        "id": "Jp9ER5O1_4kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "target_transform = transforms.Compose(\n",
        "    [lambda x:torch.LongTensor([x]),\n",
        "      lambda x:nn.functional.one_hot(x,10)])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform,\n",
        "                                        target_transform=target_transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform,\n",
        "                                       target_transform=target_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "prGwsW0m_nJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(images, labels=None, predicted_labels=None):\n",
        "    # Using torchvision to make a grid of the images\n",
        "    img = torchvision.utils.make_grid(images)\n",
        "\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    img = img.permute(1, 2, 0)\n",
        "\n",
        "    # Plotting the grid\n",
        "    fig, ax = plt.subplots(figsize=(12, 48))\n",
        "    plt.imshow(img)\n",
        "\n",
        "    if predicted_labels is not None:\n",
        "        # labels prédits si elles existent\n",
        "        ax.set_xlabel('Predicted labels', fontsize=18, labelpad=12)\n",
        "        ax.set_xticks(torch.arange(len(images)) * 35 + 20)\n",
        "        ax.set_xticklabels([classes[predicted_labels[j]]\n",
        "                            for j in range(len(images))], fontsize=14)\n",
        "\n",
        "    # labels ground truth\n",
        "    gax = ax.secondary_xaxis('top')\n",
        "    # gax.set_xlabel('Ground truth', fontsize=18, labelpad=12)\n",
        "    gax.set_xticks(torch.arange(len(images)) * 35 + 20)\n",
        "    if labels is not None:\n",
        "        gax.set_xticklabels([classes[torch.sum(labels[j]*torch.arange(labels[j].size(1)))]\n",
        "                         for j in range(len(images))], fontsize=14)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qrjdHoJW_62Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test mixup"
      ],
      "metadata": {
        "id": "w_P4slu9FH--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Images random du train\n",
        "dataiter = iter(trainloader)\n",
        "images1, labels1 = next(dataiter)\n",
        "images2, labels2 = next(dataiter)"
      ],
      "metadata": {
        "id": "cccq7dAIAEIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(images1, labels1)\n",
        "imshow(images2, labels2)"
      ],
      "metadata": {
        "id": "2CzIJfzmAGtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Essayer Mixup avec les arguments par défaut"
      ],
      "metadata": {
        "id": "szXeiKSfHS8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mixup = MixUpModule()"
      ],
      "metadata": {
        "id": "0t57KCmnAIha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_x, mixed_y = mixup(images1, images2, labels1, labels2)\n",
        "print(f\"lambda = {mixup.get_last_lambda():.3f}\")\n",
        "print(mixed_y)"
      ],
      "metadata": {
        "id": "Sh-OUVXzAPHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(mixed_x)"
      ],
      "metadata": {
        "id": "IrVrO8daA9DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Essayer Mixup avec différentes valeurs de alpha"
      ],
      "metadata": {
        "id": "AHX42_B7HwEm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MOxPCiYeHwg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Essayer Mixup avec des valeurs que vous fixez pour lambda, sans sampling"
      ],
      "metadata": {
        "id": "_Tv05XmCHYnM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OpHWZNb9DRsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AszvioXHEXoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN avec et sans Mixup\n",
        "\n",
        "Entraîner et tester sur CIFAR10 un réseau CNN from scratch sans et avec Mixup.\n",
        "\n",
        "!!! Attention changer le batch size à 64 et non 4 dans la cellule en haut du notebook pour les dataloaders, sinon ce sera très très lent (et moins performant)"
      ],
      "metadata": {
        "id": "824EWm9hLFew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "id": "ItuGgfO-NZL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(testloader, trainloader, model, opt, crit, use_mixup=False, n_epoch=2, loss_every=500):\n",
        "    \"\"\"\n",
        "    Entraînement d'un modèle et plot des courbes de loss et accuracy\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    losses = []\n",
        "    acc = []\n",
        "    for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "        print(f\"Epoch {epoch}.\")\n",
        "\n",
        "        running_loss = []\n",
        "        running_acc = []\n",
        "        print(\"Train.\")\n",
        "        for i, data in tqdm_notebook(enumerate(trainloader), total=len(trainloader)):\n",
        "\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Mettre à zero les gradients des poids du modèle\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            if use_mixup:\n",
        "              outputs, mixed_labels = model(inputs, labels)\n",
        "              _, mixed_labels_ = mixed_labels.max(dim=1)\n",
        "              loss = crit(outputs, mixed_labels_.float())\n",
        "            else:\n",
        "              outputs = model(inputs)\n",
        "              _, labels_ = labels.max(dim=1)\n",
        "              loss = crit(outputs, labels_.float())\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            running_loss.append(loss.item())\n",
        "            running_acc.append((predicted == labels).sum().item() / labels.size(0))\n",
        "\n",
        "            # calculer une moyenne\n",
        "            if i % loss_every:\n",
        "                losses.append(np.mean(running_loss))\n",
        "                acc.append(np.mean(running_acc))\n",
        "\n",
        "                running_loss = []\n",
        "                running_acc = []\n",
        "\n",
        "        test_acc = accuracy(testloader, model)\n",
        "        print(f\"Test accuracy: {test_acc:.3f}\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2)\n",
        "    axes[0].plot(losses)\n",
        "    axes[1].plot(acc)\n",
        "\n",
        "    axes[0].set_ylabel(\"Train loss\")\n",
        "    axes[1].set_ylabel(\"Train acc\")\n",
        "    plt.show()\n",
        "    print('Apprentissage terminé')\n",
        "\n",
        "\n",
        "def accuracy(loader, model):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        loader: data loader sur lequel on veut calculer une accuracy\n",
        "        model\n",
        "    Returns:\n",
        "        Accuracy\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        model.eval()  # remove potential dropout, ...\n",
        "        n_correct = 0\n",
        "        n_total = 0\n",
        "        for i, data in tqdm_notebook(enumerate(loader), total=len(loader)):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            n_correct += (predicted == labels).sum()\n",
        "            n_total += labels.size(0)\n",
        "        return n_correct / n_total\n",
        "\n",
        "\n",
        "def validate(loader, model):\n",
        "    \"\"\"\n",
        "    Plot des predictions faites avec model, affiche l'accuracy\n",
        "    \"\"\"\n",
        "    dataiter = iter(loader)\n",
        "    # Get one batch of data\n",
        "    images, labels = next(dataiter)\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "    accuracy_model = accuracy(loader, model)\n",
        "\n",
        "    # print images\n",
        "    print(f'Accuracy: {accuracy_model.detach().cpu().item():.3f}')\n",
        "\n",
        "    imshow(images[:4].detach().cpu(), labels[:4], predicted_labels=predictions[:4])\n"
      ],
      "metadata": {
        "id": "ehNOwC5uNM3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sans mixup"
      ],
      "metadata": {
        "id": "UGvSBKFpLHqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-oC3cSgHM-tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "J3C9X6VYLGss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(testloader, trainloader, net, optimizer, criterion, n_epoch=10)"
      ],
      "metadata": {
        "id": "LlXNYLKgNtpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate(testloader, net)"
      ],
      "metadata": {
        "id": "M54RGVquN-Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avec mixup"
      ],
      "metadata": {
        "id": "O5A6zfMqLLj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NetMixup(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetMixup, self).__init__()\n",
        "        self.mixup = MixUpModule()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x, labels=None):\n",
        "\n",
        "        if labels is not None:\n",
        "          batch_size = x.size(0)\n",
        "          indexes = torch.randperm(batch_size)\n",
        "          x_shuffle = x[indexes]\n",
        "          labels_shuffle = labels[indexes]\n",
        "          x, labels_mix = self.mixup(x, x_shuffle, labels, labels_shuffle)\n",
        "\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        if labels is not None:\n",
        "          return x, labels_mix.long()\n",
        "        return x"
      ],
      "metadata": {
        "id": "ftkgmMZiLM18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netMixup = NetMixup().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(netMixup.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "SMNuQ31sPeir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(testloader, trainloader, netMixup, optimizer, criterion, use_mixup=True, n_epoch=30)"
      ],
      "metadata": {
        "id": "LEXlsKthQQPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_mEggrNYQUjH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}