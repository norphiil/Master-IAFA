
@incollection{singhania_3han_2017,
	title = {3HAN: A Deep Neural Network for Fake News Detection},
	volume = {10635},
	url = {http://arxiv.org/abs/2306.12014},
	shorttitle = {3HAN},
	abstract = {The rapid spread of fake news is a serious problem calling for {AI} solutions. We employ a deep learning based automated detector through a three level hierarchical attention network (3HAN) for fast, accurate detection of fake news. 3HAN has three levels, one each for words, sentences, and the headline, and constructs a news vector: an effective representation of an input news article, by processing an article in an hierarchical bottom-up manner. The headline is known to be a distinguishing feature of fake news, and furthermore, relatively few words and sentences in an article are more important than the rest. 3HAN gives a differential importance to parts of an article, on account of its three layers of attention. By experiments on a large real-world data set, we observe the effectiveness of 3HAN with an accuracy of 96.77\%. Unlike some other deep learning models, 3HAN provides an understandable output through the attention weights given to different parts of an article, which can be visualized through a heatmap to enable further manual fact checking.},
	pages = {572--581},
	author = {Singhania, Sneha and Fernandez, Nigel and Rao, Shrisha},
	urldate = {2025-02-02},
	date = {2017},
	doi = {10.1007/978-3-319-70096-0_59},
	eprinttype = {arxiv},
	eprint = {2306.12014 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Social and Information Networks},
	file = {Preprint PDF:C\:\\Users\\norph\\Zotero\\storage\\H6KAZG4W\\Singhania et al. - 2017 - 3HAN A Deep Neural Network for Fake News Detection.pdf:application/pdf;Snapshot:C\:\\Users\\norph\\Zotero\\storage\\6AJHBFC6\\2306.html:text/html},
}

@article{alim_al_ayub_ahmed_et_al_detecting_2021,
	title = {Detecting Fake News using Machine Learning: A Systematic Literature Review},
	volume = {58},
	rights = {https://creativecommons.org/licenses/by/4.0},
	issn = {0033-3077},
	url = {http://psychologyandeducation.net/pae/index.php/pae/article/view/1046},
	doi = {10.17762/pae.v58i1.1046},
	shorttitle = {Detecting Fake News using Machine Learning},
	abstract = {Internet is one of the important inventions and a large number of persons are its users. These persons use this for different purposes. There are different social media platforms that are accessible to these users. Any user can make a post or spread the news through these online platforms. These platforms do not verify the users or their posts. So some of the users try to spread fake news through these platforms. These fake news can be a propaganda against an individual, society, organization or political party. A human being is unable to detect all these fake news. So there is a need for machine learning classifiers that can detect these fake news automatically. Use of machine learning classifiers for detecting the fake news is described in this systematic literature review.},
	pages = {1932--1939},
	number = {1},
	journaltitle = {Psychology and Education Journal},
	shortjournal = {pae},
	author = {{Alim Al Ayub Ahmed Et Al.}},
	urldate = {2025-02-02},
	date = {2021-01-01},
	langid = {english},
	note = {Number: 1},
	file = {PDF:C\:\\Users\\norph\\Zotero\\storage\\FDU5A9U4\\Et Al. - 2021 - Detecting Fake News using Machine Learning A Systematic Literature Review.pdf:application/pdf},
}

@article{roumeliotis_fake_2025,
	title = {Fake News Detection and Classification: A Comparative Study of Convolutional Neural Networks, Large Language Models, and Natural Language Processing Models},
	volume = {17},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1999-5903},
	url = {https://www.mdpi.com/1999-5903/17/1/28},
	doi = {10.3390/fi17010028},
	shorttitle = {Fake News Detection and Classification},
	abstract = {In an era where fake news detection has become a pressing issue due to its profound impacts on public opinion, democracy, and social trust, accurately identifying and classifying false information is a critical challenge. In this study, the effectiveness is investigated of advanced machine learning models—convolutional neural networks ({CNNs}), bidirectional encoder representations from transformers ({BERT}), and generative pre-trained transformers ({GPTs})—for robust fake news classification. Each model brings unique strengths to the task, from {CNNs}’ pattern recognition capabilities to {BERT} and {GPTs}’ contextual understanding in the embedding space. Our results demonstrate that the fine-tuned {GPT}-4 Omni models achieve 98.6\% accuracy, significantly outperforming traditional models like {CNNs}, which achieved only 58.6\%. Notably, the smaller {GPT}-4o mini model performed comparably to its larger counterpart, highlighting the cost-effectiveness of smaller models for specialized tasks. These findings emphasize the importance of fine-tuning large language models ({LLMs}) to optimize the performance for complex tasks such as fake news classifier development, where capturing subtle contextual relationships in text is crucial. However, challenges such as computational costs and suboptimal outcomes in zero-shot classification persist, particularly when distinguishing fake content from legitimate information. By highlighting the practical application of fine-tuned {LLMs} and exploring the potential of few-shot learning for fake news detection, this research provides valuable insights for news organizations seeking to implement scalable and accurate solutions. Ultimately, this work contributes to fostering transparency and integrity in journalism through innovative {AI}-driven methods for fake news classification and automated fake news classifier systems.},
	pages = {28},
	number = {1},
	journaltitle = {Future Internet},
	author = {Roumeliotis, Konstantinos I. and Tselikas, Nikolaos D. and Nasiopoulos, Dimitrios K.},
	urldate = {2025-02-02},
	date = {2025-01},
	langid = {english},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {bidirectional encoder representations from transformers ({BERT}), convolutional neural networks ({CNNs}), disinformation, fake news classification, fake news classifier, fake news detection, generative pre-trained transformers ({GPTs}), information integrity, misinformation, natural language processing ({NLP})},
	file = {Full Text PDF:C\:\\Users\\norph\\Zotero\\storage\\PQ9RNEP6\\Roumeliotis et al. - 2025 - Fake News Detection and Classification A Comparative Study of Convolutional Neural Networks, Large.pdf:application/pdf},
}

@article{beseiso_context-enhanced_2025,
	title = {A Context-Enhanced Model for Fake News Detection},
	volume = {15},
	rights = {Copyright (c) 2024 Majdi Beseiso, Saleh Al-Zahrani},
	issn = {1792-8036},
	url = {https://etasr.com/index.php/ETASR/article/view/9192},
	doi = {10.48084/etasr.9192},
	abstract = {Received: 7 October 2024 {\textbar} Revised: 12 November 2024 {\textbar} Accepted: 16 November 2024 {\textbar} Online: 22 December 2024Corresponding author: Majdi Beseiso},
	pages = {19128--19135},
	number = {1},
	journaltitle = {Engineering, Technology \& Applied Science Research},
	author = {Beseiso, Majdi and Al-Zahrani, Saleh},
	urldate = {2025-02-02},
	date = {2025-02-02},
	langid = {english},
	note = {Number: 1},
	keywords = {convolutional neural networks, fake news, long short-term memory, natural language processing, word2vec embedding},
	file = {Full Text PDF:C\:\\Users\\norph\\Zotero\\storage\\6YHEDDIW\\Beseiso et Al-Zahrani - 2025 - A Context-Enhanced Model for Fake News Detection.pdf:application/pdf},
}

@article{verma_welfake_2021,
	title = {{WELFake}: Word Embedding Over Linguistic Features for Fake News Detection},
	volume = {8},
	issn = {2329-924X},
	url = {https://ieeexplore.ieee.org/document/9395133},
	doi = {10.1109/TCSS.2021.3068519},
	shorttitle = {{WELFake}},
	abstract = {Social media is a popular medium for the dissemination of real-time news all over the world. Easy and quick information proliferation is one of the reasons for its popularity. An extensive number of users with different age groups, gender, and societal beliefs are engaged in social media websites. Despite these favorable aspects, a significant disadvantage comes in the form of fake news, as people usually read and share information without caring about its genuineness. Therefore, it is imperative to research methods for the authentication of news. To address this issue, this article proposes a two-phase benchmark model named {WELFake} based on word embedding ({WE}) over linguistic features for fake news detection using machine learning classification. The first phase preprocesses the data set and validates the veracity of news content by using linguistic features. The second phase merges the linguistic feature sets with {WE} and applies voting classification. To validate its approach, this article also carefully designs a novel {WELFake} data set with approximately 72 000 articles, which incorporates different data sets to generate an unbiased classification output. Experimental results show that the {WELFake} model categorizes the news in real and fake with a 96.73\% which improves the overall accuracy by 1.31\% compared to bidirectional encoder representations from transformer ({BERT}) and 4.25\% compared to convolutional neural network ({CNN}) models. Our frequency-based and focused analyzing writing patterns model outperforms predictive-based related works implemented using the Word2vec {WE} method by up to 1.73\%.},
	pages = {881--893},
	number = {4},
	journaltitle = {{IEEE} Transactions on Computational Social Systems},
	author = {Verma, Pawan Kumar and Agrawal, Prateek and Amorim, Ivone and Prodan, Radu},
	urldate = {2025-02-03},
	date = {2021-08},
	note = {Number: 4
Conference Name: {IEEE} Transactions on Computational Social Systems},
	keywords = {Bidirectional encoder representations from transformer ({BERT}), Bit error rate, convolutional neural network ({CNN}), Data models, fake news, Feature extraction, linguistic feature, Linguistics, machine learning ({ML}), Social networking (online), text classification, Training, Vegetation, voting classifier, word embedding ({WE})},
	file = {Full Text PDF:C\:\\Users\\norph\\Zotero\\storage\\BHKRKQAB\\Verma et al. - 2021 - WELFake Word Embedding Over Linguistic Features for Fake News Detection.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\norph\\Zotero\\storage\\62TFWYDD\\9395133.html:text/html},
}

@article{yang_unsupervised_2019,
	title = {Unsupervised Fake News Detection on Social Media: A Generative Approach},
	volume = {33},
	rights = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4508},
	doi = {10.1609/aaai.v33i01.33015644},
	shorttitle = {Unsupervised Fake News Detection on Social Media},
	abstract = {Social media has become one of the main channels for people to access and consume news, due to the rapidness and low cost of news dissemination on it. However, such properties of social media also make it a hotbed of fake news dissemination, bringing negative impacts on both individuals and society. Therefore, detecting fake news has become a crucial problem attracting tremendous research effort. Most existing methods of fake news detection are supervised, which require an extensive amount of time and labor to build a reliably annotated dataset. In search of an alternative, in this paper, we investigate if we could detect fake news in an unsupervised manner. We treat truths of news and users’ credibility as latent random variables, and exploit users’ engagements on social media to identify their opinions towards the authenticity of news. We leverage a Bayesian network model to capture the conditional dependencies among the truths of news, the users’ opinions, and the users’ credibility. To solve the inference problem, we propose an efficient collapsed Gibbs sampling approach to infer the truths of news and the users’ credibility without any labelled data. Experiment results on two datasets show that the proposed method significantly outperforms the compared unsupervised methods.},
	pages = {5644--5651},
	number = {1},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Yang, Shuo and Shu, Kai and Wang, Suhang and Gu, Renjie and Wu, Fan and Liu, Huan},
	urldate = {2025-02-03},
	date = {2019-07-17},
	langid = {english},
	note = {Number: 01},
	file = {Full Text PDF:C\:\\Users\\norph\\Zotero\\storage\\UPPVZU99\\Yang et al. - 2019 - Unsupervised Fake News Detection on Social Media A Generative Approach.pdf:application/pdf},
}

@article{alghamdi_towards_2023,
	title = {Towards {COVID}-19 fake news detection using transformer-based models},
	volume = {274},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705123003921},
	doi = {10.1016/j.knosys.2023.110642},
	abstract = {The {COVID}-19 pandemic has resulted in a surge of fake news, creating public health risks. However, developing an effective way to detect such news is challenging, especially when published news involves mixing true and false information. Detecting {COVID}-19 fake news has become a critical task in the field of natural language processing ({NLP}). This paper explores the effectiveness of several machine learning algorithms and fine-tuning pre-trained transformer-based models, including Bidirectional Encoder Representations from Transformers ({BERT}) and {COVID}-Twitter-{BERT} ({CT}-{BERT}), for {COVID}-19 fake news detection. We evaluate the performance of different downstream neural network structures, such as {CNN} and {BiGRU} layers, added on top of {BERT} and {CT}-{BERT} with frozen or unfrozen parameters. Our experiments on a real-world {COVID}-19 fake news dataset demonstrate that incorporating {BiGRU} on top of the {CT}-{BERT} model achieves outstanding performance, with a state-of-the-art F1 score of 98\%. These results have significant implications for mitigating the spread of {COVID}-19 misinformation and highlight the potential of advanced machine learning models for fake news detection.},
	pages = {110642},
	journaltitle = {Knowledge-Based Systems},
	shortjournal = {Knowledge-Based Systems},
	author = {Alghamdi, Jawaher and Lin, Yuqing and Luo, Suhuai},
	urldate = {2025-02-03},
	date = {2023-08-15},
	keywords = {{COVID}-19, Fake news, Misinformation, Pre-trained transformer models, Social media},
	file = {PubMed Central Full Text PDF:C\:\\Users\\norph\\Zotero\\storage\\53G32BEV\\Alghamdi et al. - 2023 - Towards COVID-19 fake news detection using transformer-based models.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\norph\\Zotero\\storage\\IWACJAUT\\S0950705123003921.html:text/html},
}

@article{conroy_automatic_2015,
	title = {Automatic deception detection: Methods for finding fake news},
	volume = {52},
	rights = {Copyright © 2015 by Association for Information Science and Technology},
	issn = {2373-9231},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pra2.2015.145052010082},
	doi = {10.1002/pra2.2015.145052010082},
	shorttitle = {Automatic deception detection},
	abstract = {This research surveys the current state-of-the-art technologies that are instrumental in the adoption and development of fake news detection. “Fake news detection” is defined as the task of categorizing news along a continuum of veracity, with an associated measure of certainty. Veracity is compromised by the occurrence of intentional deceptions. The nature of online news publication has changed, such that traditional fact checking and vetting from potential deception is impossible against the flood arising from content generators, as well as various formats and genres. The paper provides a typology of several varieties of veracity assessment methods emerging from two major categories – linguistic cue approaches (with machine learning), and network analysis approaches. We see promise in an innovative hybrid approach that combines linguistic cue and machine learning, with network-based behavioral data. Although designing a fake news detector is not a straightforward problem, we propose operational guidelines for a feasible fake news detecting system.},
	pages = {1--4},
	number = {1},
	journaltitle = {Proceedings of the Association for Information Science and Technology},
	author = {Conroy, Nadia K. and Rubin, Victoria L. and Chen, Yimin},
	urldate = {2025-02-03},
	date = {2015},
	langid = {english},
	note = {Number: 1
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pra2.2015.145052010082},
	keywords = {automation, Deception detection, fake news detection, fraud, knowledge networks, methods, news verification, predictive modelling, {SVM}, veracity assessment},
	file = {Full Text PDF:C\:\\Users\\norph\\Zotero\\storage\\6I22ZSI5\\Conroy et al. - 2015 - Automatic deception detection Methods for finding fake news.pdf:application/pdf;Snapshot:C\:\\Users\\norph\\Zotero\\storage\\P8ZLJ394\\pra2.2015.html:text/html},
}

@article{kaliyar_fakebert_2021,
	title = {{FakeBERT}: Fake news detection in social media with a {BERT}-based deep learning approach},
	volume = {80},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-020-10183-2},
	doi = {10.1007/s11042-020-10183-2},
	shorttitle = {{FakeBERT}},
	abstract = {In the modern era of computing, the news ecosystem has transformed from old traditional print media to social media outlets. Social media platforms allow us to consume news much faster, with less restricted editing results in the spread of fake news at an incredible pace and scale. In recent researches, many useful methods for fake news detection employ sequential neural networks to encode news content and social context-level information where the text sequence was analyzed in a unidirectional way. Therefore, a bidirectional training approach is a priority for modelling the relevant information of fake news that is capable of improving the classification performance with the ability to capture semantic and long-distance dependencies in sentences. In this paper, we propose a {BERT}-based (Bidirectional Encoder Representations from Transformers) deep learning approach ({FakeBERT}) by combining different parallel blocks of the single-layer deep Convolutional Neural Network ({CNN}) having different kernel sizes and filters with the {BERT}. Such a combination is useful to handle ambiguity, which is the greatest challenge to natural language understanding. Classification results demonstrate that our proposed model ({FakeBERT}) outperforms the existing models with an accuracy of 98.90\%.},
	pages = {11765--11788},
	number = {8},
	journaltitle = {Multimedia Tools and Applications},
	shortjournal = {Multimed Tools Appl},
	author = {Kaliyar, Rohit Kumar and Goswami, Anurag and Narang, Pratik},
	urldate = {2025-02-03},
	date = {2021-03-01},
	langid = {english},
	note = {Number: 8},
	keywords = {Artificial Intelligence, {BERT}, Deep learning, Fake news, Neural network, Social media},
	file = {Full Text PDF:C\:\\Users\\norph\\Zotero\\storage\\RIL47Q7N\\Kaliyar et al. - 2021 - FakeBERT Fake news detection in social media with a BERT-based deep learning approach.pdf:application/pdf},
}

@article{truica_its_2023,
	title = {It’s All in the Embedding! Fake News Detection Using Document Embeddings},
	volume = {11},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-7390},
	url = {https://www.mdpi.com/2227-7390/11/3/508},
	doi = {10.3390/math11030508},
	abstract = {With the current shift in the mass media landscape from journalistic rigor to social media, personalized social media is becoming the new norm. Although the digitalization progress of the media brings many advantages, it also increases the risk of spreading disinformation, misinformation, and malformation through the use of fake news. The emergence of this harmful phenomenon has managed to polarize society and manipulate public opinion on particular topics, e.g., elections, vaccinations, etc. Such information propagated on social media can distort public perceptions and generate social unrest while lacking the rigor of traditional journalism. Natural Language Processing and Machine Learning techniques are essential for developing efficient tools that can detect fake news. Models that use the context of textual data are essential for resolving the fake news detection problem, as they manage to encode linguistic features within the vector representation of words. In this paper, we propose a new approach that uses document embeddings to build multiple models that accurately label news articles as reliable or fake. We also present a benchmark on different architectures that detect fake news using binary or multi-labeled classification. We evaluated the models on five large news corpora using accuracy, precision, and recall. We obtained better results than more complex state-of-the-art Deep Neural Network models. We observe that the most important factor for obtaining high accuracy is the document encoding, not the classification model's complexity.},
	pages = {508},
	number = {3},
	journaltitle = {Mathematics},
	author = {Truică, Ciprian-Octavian and Apostol, Elena-Simona},
	urldate = {2025-02-03},
	date = {2023-01},
	langid = {english},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {classification models, deep learning, document embeddings, fake news detection, machine learning, text analysis},
	file = {Full Text PDF:C\:\\Users\\norph\\Zotero\\storage\\E7MXRH4F\\Truică et Apostol - 2023 - It’s All in the Embedding! Fake News Detection Using Document Embeddings.pdf:application/pdf},
}

@article{rai_fake_2022,
	title = {Fake News Classification using transformer based enhanced {LSTM} and {BERT}},
	volume = {3},
	issn = {26663074},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666307422000092},
	doi = {10.1016/j.ijcce.2022.03.003},
	abstract = {Fake News has been a concern all over the world and social media has only ampliﬁed this phenomenon. Fake News has been aﬀecting the world on a large scale as these are targeted to sway the decisions of the crowd in a particular direction. Since manually verifying the legitimacy of news is very hard and costly, there has been a great interest of researchers in this ﬁeld. Diﬀerent approaches to identifying fake news were examined, such as content-based classiﬁcation, social context-based classiﬁcation, image-based classiﬁcation, sentimentbased classiﬁcation, and hybrid context-based classiﬁcation. This paper aims to propose a model for fake news classiﬁcation based on news titles, following the content-based classiﬁcation approach. The model uses a {BERT} model with its outputs connected to an {LSTM} layer. Training and evaluation of the model were done on the {FakeNewsNet} dataset which contains two sub-datasets, {PolitiFact} and {GossipCop}. A comparison of the model with base classiﬁcation models has been done. A vanilla {BERT} model has also been trained on the dataset under similar constraints as the proposed model has to evaluate the impact same using an {LSTM} layer. The results obtained showed a 2.50\% and 1.10\% increase in accuracy on {PolitiFact} and {GossipCop} datasets respectively over the vanilla pre-trained {BERT} model.},
	pages = {98--105},
	journaltitle = {International Journal of Cognitive Computing in Engineering},
	shortjournal = {International Journal of Cognitive Computing in Engineering},
	author = {Rai, Nishant and Kumar, Deepika and Kaushik, Naman and Raj, Chandan and Ali, Ahad},
	urldate = {2025-02-03},
	date = {2022-06},
	langid = {english},
	file = {PDF:C\:\\Users\\norph\\Zotero\\storage\\ECNRF853\\Rai et al. - 2022 - Fake News Classification using transformer based enhanced LSTM and BERT.pdf:application/pdf},
}

@misc{william_yang_wang_liar_2017,
	title = {"Liar, Liar Pants on Fire": A New Benchmark Dataset for Fake News Detection},
	url = {http://arxiv.org/abs/1705.00648},
	doi = {10.48550/arXiv.1705.00648},
	shorttitle = {"Liar, Liar Pants on Fire"},
	abstract = {Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts. However, statistical approaches to combating fake news has been dramatically limited by the lack of labeled benchmark datasets. In this paper, we present {LIAR}: a new, publicly available dataset for fake news detection. We collected a decade-long, 12.8K manually labeled short statements in various contexts from {POLITIFACT}.{COM}, which provides detailed analysis report and links to source documents for each case. This dataset can be used for fact-checking research as well. Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type. Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns. We have designed a novel, hybrid convolutional neural network to integrate metadata with text. We show that this hybrid approach can improve a text-only deep learning model.},
	number = {{arXiv}:1705.00648},
	publisher = {{arXiv}},
	author = {{William Yang Wang}},
	urldate = {2025-02-03},
	date = {2017-05-01},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1705.00648 [cs]},
	note = {Issue: {arXiv}:1705.00648},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society},
	file = {PDF:C\:\\Users\\norph\\Zotero\\storage\\5DUWTD49\\Wang - 2017 - Liar, Liar Pants on Fire A New Benchmark Dataset for Fake News Detection.pdf:application/pdf},
}

@article{hu_bad_2024,
	title = {Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection},
	volume = {38},
	issn = {2374-3468, 2159-5399},
	url = {http://arxiv.org/abs/2309.12247},
	doi = {10.1609/aaai.v38i20.30214},
	shorttitle = {Bad Actor, Good Advisor},
	abstract = {Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models ({SLMs}) due to their knowledge and capability limitations. Recent advances in large language models ({LLMs}) have shown remarkable performance in various tasks, but whether and how {LLMs} could help with fake news detection remains underexplored. In this paper, we investigate the potential of {LLMs} in fake news detection. First, we conduct an empirical study and find that a sophisticated {LLM} such as {GPT} 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic {SLM}, fine-tuned {BERT}. Our subsequent analysis attributes such a gap to the {LLM}’s inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current {LLMs} may not substitute fine-tuned {SLMs} in fake news detection but can be a good advisor for {SLMs} by providing multi-perspective instructive rationales. To instantiate this proposal, we design an adaptive rationale guidance network for fake news detection ({ARG}), in which {SLMs} selectively acquire insights on news analysis from the {LLMs}’ rationales. We further derive a rationale-free version of {ARG} by distillation, namely {ARGD}, which services cost-sensitive scenarios without querying {LLMs}. Experiments on two realworld datasets demonstrate that {ARG} and {ARGD} outperform three types of baseline methods, including {SLM}-based, {LLM}-based, and combinations of small and large language models.},
	pages = {22105--22113},
	number = {20},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	shortjournal = {{AAAI}},
	author = {Hu, Beizhe and Sheng, Qiang and Cao, Juan and Shi, Yuhui and Li, Yang and Wang, Danding and Qi, Peng},
	urldate = {2025-02-19},
	date = {2024-03-24},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2309.12247 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
	file = {PDF:C\:\\Users\\norph\\Zotero\\storage\\8X2BT6YF\\Hu et al. - 2024 - Bad Actor, Good Advisor Exploring the Role of Large Language Models in Fake News Detection.pdf:application/pdf},
}

@misc{reuterfake,
  author = {press.is},
  title = {Measuring the reach of “fake news” and online disinformation in Europe},
  year = {2018},
  url = {https://www.press.is/static/files/frettamyndir/reuterfake.pdf},
}

@misc{statista_fake_news,
  author = {Statista},
  title = {Fake news: opinion on most affected topics in France},
  year = {2024},
  url = {https://www.statista.com/statistics/1198660/fake-news-most-affected-topics-young-people-opinion-france/},
}

@misc{statista_spread,
  author = {Statista},
  title = {Fake news: spread platforms on the Internet in France},
  year = {2024},
  url = {https://www.statista.com/statistics/1198673/fake-news-spread-ways-internet-france/},
}
