{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5hmV8eaS9Nm"
      },
      "source": [
        "# Réseaux Recursifs (RNNs) et Modèles de Langage\n",
        "Pour ce TP nous allons explorer les RNNs et notamment les LSTMs. Nous allons essayer d'utiliser un RNN pour apprendre des séquences des mots (un texte) et ensuite générer de nouvelles séquences. \n",
        "\n",
        "Néanmoins, avant cela nous allons examiner la structure basique d'un LSTM en utilisant une entrée aléatoire. Même si plus tard nous allons avoir du texte en entrée, les LSTMs fonctionnent avec des nombres. Nous allons voir plus tard comment passer du texte aux tenseurs. Pour l'instant voici un tenseur 3x8 aléatoire. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "m5XQWEfa7w8q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "from collections import Counter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "r7DqeDD-o96j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[63, 51, 47, 43,  8,  7, 97,  1],\n",
            "        [32, 67, 74, 84, 63, 63,  7, 58],\n",
            "        [11, 81, 32, 63, 40, 73, 59, 78]])\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#entrée\n",
        "x = torch.randint(1, 100, (3, 8))\n",
        "print(x)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b4gWwcV2qQFs"
      },
      "source": [
        "Nous allons passer cet entrée aléatoire à une couche embedding, parce que les embeddings des mots peuvent mieux  representer le contexte et sont plus efficaces que les representations one-hot. \n",
        "\n",
        "Pour Pytorch nous avons besoin d'utiliser `nn.Embedding` afin de créer cette couche, qui prend en entrée la taille du vocabulaire et la longueur de vecteur de mot souhaitée. Vous pouvez éventuellement fournir un index de padding, pour indiquer l'index de l'élément de padding dans la matrice qui va représenter une phrase. Le padding sert à mettre ensemble plusieurs phrases dans un minibatch pour les mettre toutes à la même longueur.\n",
        "\n",
        "\n",
        "Dans l'exemple suivant, notre vocabulaire se compose de 100 mots, incluant l'élément spécial du padding, pour lequel on a choisi de donner l'indice 0.\n",
        "\n",
        "Remarque : dans cet exemple, le padding ne sert pas...\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Que représente `x` dans notre contexte NLP ?\n",
        "\n",
        "Dans ce contexte NLP, x représente les données d'entrée, c'est-à-dire le texte brut qui sera traité par le modèle de traitement du langage naturel.\n",
        "\n",
        "Quelle est la taille des tenseurs issus de `model1` de la cellule suivante ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "uXLUDsdtrjH2"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\norph\\Documents\\M1-IAFA\\M1S2-IAFA\\Apprentissage automatique 1\\TP4\\TP_RNN_Modele_de_Langage.ipynb Cell 6\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/norph/Documents/M1-IAFA/M1S2-IAFA/Apprentissage%20automatique%201/TP4/TP_RNN_Modele_de_Langage.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(\u001b[39m100\u001b[39m, \u001b[39m7\u001b[39m, padding_idx\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/norph/Documents/M1-IAFA/M1S2-IAFA/Apprentissage%20automatique%201/TP4/TP_RNN_Modele_de_Langage.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m out1 \u001b[39m=\u001b[39m model1(x)\n",
            "File \u001b[1;32mc:\\Users\\norph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1357\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1353\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1355\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1356\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1357\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1358\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\norph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
            "File \u001b[1;32mc:\\Users\\norph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"
          ]
        }
      ],
      "source": [
        "model1 = nn.Embedding(100, 7, padding_idx=0).to(device)\n",
        "\n",
        "out1 = model1(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWczP6zGr7-5"
      },
      "source": [
        "Nous passons la sortie de la couche embedding dans une couche LSTM qui prend en entrée la longeur du vecteur representant le mot, la longueur de la couche cachée, et le nombre des couches. La couche LSTM sort trois choses, à quoi correspondent chacune d'entre elles ? Quelles sont leurs tailles ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SErXwFhftWgF"
      },
      "outputs": [],
      "source": [
        "model2 = nn.LSTM(input_size=7, hidden_size=5,\n",
        "                 num_layers=1, batch_first=True).to(device)\n",
        "\n",
        "out, (ht, ct) = model2(out1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA9OqdSCo-8-"
      },
      "source": [
        "Passons maintaiannt au modèle de langage. Pour les données nous allons utiliser un ensemble de blagues recueillis sur Reddit, inspiré par un tutoriel de Domas Bitvinskas.   \n",
        "\n",
        "\n",
        "## Le modèle \n",
        "Voici un premier modèle utilisant trois couches LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfA98RjmS5ZJ"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embedding_dim,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFW6l7vVS7Gr"
      },
      "source": [
        "\n",
        "C'est un model LSTM avec Pytorch assez standard. Comme expliqué dans l'introduction, le but de la couche `Embedding` est de convertir les mots (leur indice dans un dictionnaire) en vecteurs. La fonction `init_state` est appelée au début de chaque époque.  \n",
        "\n",
        "## Données \n",
        "Téléchargons les données.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_4Zpmks-tn0"
      },
      "source": [
        "\n",
        "Il s'agit d'un fichier tsv de la forme `ID,Joke` ou `ID` signifie simplement l'identifiant de la « blague » et `Joke` le texte. Afin de pouvoir traiter les données nous aurons besoin d'utiliser la class `Dataset`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy0v3k37Xht1"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  \n",
        "    def __init__(\n",
        "        self,\n",
        "        sequence_length,\n",
        "    ):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "    \n",
        "    def load_words(self):\n",
        "        train_df = pd.read_csv('reddit-cleanjokes.csv')\n",
        "        text = train_df['Joke'].str.cat(sep=' ')\n",
        "        return text.split(' ')\n",
        "    \n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.sequence_length\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3gjVI4UhYxx"
      },
      "source": [
        "Cette classe hérite de la classe `torch.utils.data.Dataset`. En plus de `__init__`,  il est nécessaire de définir deux fonctions : `__len__` et `__getitem__`. La première retourne la taille de notre ensemble des données alors que la deuxième implémente l'indexation afin que `dataset[i]` puisse être utilisé pour retourner le *i*-ème élément. Vous pouvez avoir plus de détails [ici](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class). \n",
        "\n",
        "La fonction `load_words` charge le dataset. Le but est de trouver tous les mots afin de définir la taille du vocabulaire du réseau mais également la taille de l'embedding. Deux autres fonctions `index_to_word` et `word_to_index` convertissent les mots en index et vice versa. \n",
        "\n",
        "# Entrainement \n",
        "\n",
        "Nous allons définir une fonction `train` pour entraîner notre RNN. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNCaFS1YziKO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "\n",
        "def train(dataset, model, max_epochs, sequence_length):\n",
        "    model.train()\n",
        "    dataloader = DataLoader(dataset, batch_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    for epoch in range(max_epochs):\n",
        "        state_h, state_c = model.init_state(sequence_length)\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF6YTawU0pg3"
      },
      "source": [
        "Comme vous pouvez constater la fonction train charge d'abord les données, définit comme fonction de perte Cross Entropy Loss ainsi que SGD comme optimizer et ensuite appelle le modèle pour `max_epochs`. \n",
        "\n",
        "# Prédictions \n",
        "\n",
        "Une fois que nous avons entraîné notre modèle nous pouvons ensuite faire des prédictions, en donnant une séquence des mots en entrée.   Voici une fonction nous permettant de prédire les `next_words` suivant à partir d'un `text`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuvVMi4F0ptq"
      },
      "outputs": [],
      "source": [
        "def predict(dataset, model, text, next_words=100):\n",
        "    model.eval()\n",
        "    words = text.split(' ')\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w]\n",
        "                         for w in words[i:]]]).to(device)\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "    return words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzDYV1ff0vNR"
      },
      "source": [
        "Nous sommes prêtes et prêts maintenant à entraîner notre modèle, ci-dessous un morceau du code qui nous permettra de le faire sur l'ensemble des données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnhUFjd70vXc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (embedding): Embedding(6925, 128)\n",
            "  (lstm): LSTM(128, 128, num_layers=3, dropout=0.2)\n",
            "  (fc): Linear(in_features=128, out_features=6925, bias=True)\n",
            ")\n",
            "{'epoch': 0, 'batch': 0, 'loss': 8.835650444030762}\n",
            "{'epoch': 0, 'batch': 1, 'loss': 8.834256172180176}\n",
            "{'epoch': 0, 'batch': 2, 'loss': 8.823616981506348}\n",
            "{'epoch': 0, 'batch': 3, 'loss': 8.811324119567871}\n",
            "{'epoch': 0, 'batch': 4, 'loss': 8.808272361755371}\n",
            "{'epoch': 0, 'batch': 5, 'loss': 8.791820526123047}\n",
            "{'epoch': 0, 'batch': 6, 'loss': 8.796548843383789}\n",
            "{'epoch': 0, 'batch': 7, 'loss': 8.76052474975586}\n",
            "{'epoch': 0, 'batch': 8, 'loss': 8.726407051086426}\n",
            "{'epoch': 0, 'batch': 9, 'loss': 8.656014442443848}\n",
            "{'epoch': 0, 'batch': 10, 'loss': 8.586350440979004}\n",
            "{'epoch': 0, 'batch': 11, 'loss': 8.43297004699707}\n",
            "{'epoch': 0, 'batch': 12, 'loss': 8.345458030700684}\n",
            "{'epoch': 0, 'batch': 13, 'loss': 8.248644828796387}\n",
            "{'epoch': 0, 'batch': 14, 'loss': 7.953495979309082}\n",
            "{'epoch': 0, 'batch': 15, 'loss': 7.891519546508789}\n",
            "{'epoch': 0, 'batch': 16, 'loss': 7.726036548614502}\n",
            "{'epoch': 0, 'batch': 17, 'loss': 7.685776710510254}\n",
            "{'epoch': 0, 'batch': 18, 'loss': 7.573817729949951}\n",
            "{'epoch': 0, 'batch': 19, 'loss': 7.532113075256348}\n",
            "{'epoch': 0, 'batch': 20, 'loss': 7.243362903594971}\n",
            "{'epoch': 0, 'batch': 21, 'loss': 7.656823635101318}\n",
            "{'epoch': 0, 'batch': 22, 'loss': 7.493531227111816}\n",
            "{'epoch': 0, 'batch': 23, 'loss': 7.600311279296875}\n",
            "{'epoch': 0, 'batch': 24, 'loss': 7.492918491363525}\n",
            "{'epoch': 0, 'batch': 25, 'loss': 7.267856121063232}\n",
            "{'epoch': 0, 'batch': 26, 'loss': 7.168857097625732}\n",
            "{'epoch': 0, 'batch': 27, 'loss': 7.145296096801758}\n",
            "{'epoch': 0, 'batch': 28, 'loss': 7.762772560119629}\n",
            "{'epoch': 0, 'batch': 29, 'loss': 7.842548847198486}\n",
            "{'epoch': 0, 'batch': 30, 'loss': 6.984414100646973}\n",
            "{'epoch': 0, 'batch': 31, 'loss': 7.056450366973877}\n",
            "{'epoch': 0, 'batch': 32, 'loss': 7.195468902587891}\n",
            "{'epoch': 0, 'batch': 33, 'loss': 7.444183349609375}\n",
            "{'epoch': 0, 'batch': 34, 'loss': 7.3855509757995605}\n",
            "{'epoch': 0, 'batch': 35, 'loss': 7.709752082824707}\n",
            "{'epoch': 0, 'batch': 36, 'loss': 7.631048679351807}\n",
            "{'epoch': 0, 'batch': 37, 'loss': 7.335881233215332}\n",
            "{'epoch': 0, 'batch': 38, 'loss': 7.684671878814697}\n",
            "{'epoch': 0, 'batch': 39, 'loss': 7.457263946533203}\n",
            "{'epoch': 0, 'batch': 40, 'loss': 7.782961368560791}\n",
            "{'epoch': 0, 'batch': 41, 'loss': 7.454916954040527}\n",
            "{'epoch': 0, 'batch': 42, 'loss': 7.723962783813477}\n",
            "{'epoch': 0, 'batch': 43, 'loss': 7.414648056030273}\n",
            "{'epoch': 0, 'batch': 44, 'loss': 7.322686672210693}\n",
            "{'epoch': 0, 'batch': 45, 'loss': 7.526487350463867}\n",
            "{'epoch': 0, 'batch': 46, 'loss': 7.656128406524658}\n",
            "{'epoch': 0, 'batch': 47, 'loss': 7.96327018737793}\n",
            "{'epoch': 0, 'batch': 48, 'loss': 7.33199405670166}\n",
            "{'epoch': 0, 'batch': 49, 'loss': 7.672601699829102}\n",
            "{'epoch': 0, 'batch': 50, 'loss': 7.918552875518799}\n",
            "{'epoch': 0, 'batch': 51, 'loss': 7.578434467315674}\n",
            "{'epoch': 0, 'batch': 52, 'loss': 7.103095531463623}\n",
            "{'epoch': 0, 'batch': 53, 'loss': 7.48188591003418}\n",
            "{'epoch': 0, 'batch': 54, 'loss': 7.319611549377441}\n",
            "{'epoch': 0, 'batch': 55, 'loss': 7.401691913604736}\n",
            "{'epoch': 0, 'batch': 56, 'loss': 7.500161647796631}\n",
            "{'epoch': 0, 'batch': 57, 'loss': 7.520123481750488}\n",
            "{'epoch': 0, 'batch': 58, 'loss': 7.435664653778076}\n",
            "{'epoch': 0, 'batch': 59, 'loss': 7.444795608520508}\n",
            "{'epoch': 0, 'batch': 60, 'loss': 7.30617618560791}\n",
            "{'epoch': 0, 'batch': 61, 'loss': 7.491394996643066}\n",
            "{'epoch': 0, 'batch': 62, 'loss': 7.508131980895996}\n",
            "{'epoch': 0, 'batch': 63, 'loss': 7.362751007080078}\n",
            "{'epoch': 0, 'batch': 64, 'loss': 7.508913516998291}\n",
            "{'epoch': 0, 'batch': 65, 'loss': 7.423008918762207}\n",
            "{'epoch': 0, 'batch': 66, 'loss': 7.425074577331543}\n",
            "{'epoch': 0, 'batch': 67, 'loss': 7.22227144241333}\n",
            "{'epoch': 0, 'batch': 68, 'loss': 7.428411483764648}\n",
            "{'epoch': 0, 'batch': 69, 'loss': 7.146859169006348}\n",
            "{'epoch': 0, 'batch': 70, 'loss': 7.613056182861328}\n",
            "{'epoch': 0, 'batch': 71, 'loss': 7.517307281494141}\n",
            "{'epoch': 0, 'batch': 72, 'loss': 7.418271541595459}\n",
            "{'epoch': 0, 'batch': 73, 'loss': 7.511433124542236}\n",
            "{'epoch': 0, 'batch': 74, 'loss': 7.52854585647583}\n",
            "{'epoch': 0, 'batch': 75, 'loss': 7.665243148803711}\n",
            "{'epoch': 0, 'batch': 76, 'loss': 7.374655723571777}\n",
            "{'epoch': 0, 'batch': 77, 'loss': 7.678646087646484}\n",
            "{'epoch': 0, 'batch': 78, 'loss': 7.824800968170166}\n",
            "{'epoch': 0, 'batch': 79, 'loss': 7.042092800140381}\n",
            "{'epoch': 0, 'batch': 80, 'loss': 7.35099983215332}\n",
            "{'epoch': 0, 'batch': 81, 'loss': 7.523623466491699}\n",
            "{'epoch': 0, 'batch': 82, 'loss': 7.5461745262146}\n",
            "{'epoch': 0, 'batch': 83, 'loss': 7.573478698730469}\n",
            "{'epoch': 0, 'batch': 84, 'loss': 7.389780521392822}\n",
            "{'epoch': 0, 'batch': 85, 'loss': 7.571537971496582}\n",
            "{'epoch': 0, 'batch': 86, 'loss': 7.309788703918457}\n",
            "{'epoch': 0, 'batch': 87, 'loss': 7.423763275146484}\n",
            "{'epoch': 0, 'batch': 88, 'loss': 7.3027825355529785}\n",
            "{'epoch': 0, 'batch': 89, 'loss': 7.451668739318848}\n",
            "{'epoch': 0, 'batch': 90, 'loss': 7.763368129730225}\n",
            "{'epoch': 0, 'batch': 91, 'loss': 7.296929359436035}\n",
            "{'epoch': 0, 'batch': 92, 'loss': 7.51324987411499}\n",
            "{'epoch': 0, 'batch': 93, 'loss': 7.174709320068359}\n",
            "{'epoch': 1, 'batch': 0, 'loss': 7.178388595581055}\n",
            "{'epoch': 1, 'batch': 1, 'loss': 7.168858051300049}\n",
            "{'epoch': 1, 'batch': 2, 'loss': 7.109562873840332}\n",
            "{'epoch': 1, 'batch': 3, 'loss': 7.329690933227539}\n",
            "{'epoch': 1, 'batch': 4, 'loss': 7.286091327667236}\n",
            "{'epoch': 1, 'batch': 5, 'loss': 7.295193195343018}\n",
            "{'epoch': 1, 'batch': 6, 'loss': 7.67100191116333}\n",
            "{'epoch': 1, 'batch': 7, 'loss': 7.495042324066162}\n",
            "{'epoch': 1, 'batch': 8, 'loss': 7.406343936920166}\n",
            "{'epoch': 1, 'batch': 9, 'loss': 7.2141242027282715}\n",
            "{'epoch': 1, 'batch': 10, 'loss': 7.139411926269531}\n",
            "{'epoch': 1, 'batch': 11, 'loss': 7.041774749755859}\n",
            "{'epoch': 1, 'batch': 12, 'loss': 7.076959133148193}\n",
            "{'epoch': 1, 'batch': 13, 'loss': 7.152009963989258}\n",
            "{'epoch': 1, 'batch': 14, 'loss': 6.844198226928711}\n",
            "{'epoch': 1, 'batch': 15, 'loss': 6.93669319152832}\n",
            "{'epoch': 1, 'batch': 16, 'loss': 6.720991611480713}\n",
            "{'epoch': 1, 'batch': 17, 'loss': 6.917874336242676}\n",
            "{'epoch': 1, 'batch': 18, 'loss': 6.834100723266602}\n",
            "{'epoch': 1, 'batch': 19, 'loss': 6.934019088745117}\n",
            "{'epoch': 1, 'batch': 20, 'loss': 6.65525484085083}\n",
            "{'epoch': 1, 'batch': 21, 'loss': 7.051843643188477}\n",
            "{'epoch': 1, 'batch': 22, 'loss': 7.010069847106934}\n",
            "{'epoch': 1, 'batch': 23, 'loss': 7.119027614593506}\n",
            "{'epoch': 1, 'batch': 24, 'loss': 7.068646430969238}\n",
            "{'epoch': 1, 'batch': 25, 'loss': 6.813811779022217}\n",
            "{'epoch': 1, 'batch': 26, 'loss': 6.818229675292969}\n",
            "{'epoch': 1, 'batch': 27, 'loss': 6.825070858001709}\n",
            "{'epoch': 1, 'batch': 28, 'loss': 7.237304210662842}\n",
            "{'epoch': 1, 'batch': 29, 'loss': 7.348053455352783}\n",
            "{'epoch': 1, 'batch': 30, 'loss': 6.698424339294434}\n",
            "{'epoch': 1, 'batch': 31, 'loss': 6.656031131744385}\n",
            "{'epoch': 1, 'batch': 32, 'loss': 6.800893783569336}\n",
            "{'epoch': 1, 'batch': 33, 'loss': 7.001427173614502}\n",
            "{'epoch': 1, 'batch': 34, 'loss': 6.937964916229248}\n",
            "{'epoch': 1, 'batch': 35, 'loss': 7.214437484741211}\n",
            "{'epoch': 1, 'batch': 36, 'loss': 7.129404544830322}\n",
            "{'epoch': 1, 'batch': 37, 'loss': 6.920777320861816}\n",
            "{'epoch': 1, 'batch': 38, 'loss': 7.241909027099609}\n",
            "{'epoch': 1, 'batch': 39, 'loss': 7.063179969787598}\n",
            "{'epoch': 1, 'batch': 40, 'loss': 7.307441234588623}\n",
            "{'epoch': 1, 'batch': 41, 'loss': 7.016573905944824}\n",
            "{'epoch': 1, 'batch': 42, 'loss': 7.261196136474609}\n",
            "{'epoch': 1, 'batch': 43, 'loss': 6.993677616119385}\n",
            "{'epoch': 1, 'batch': 44, 'loss': 6.922294616699219}\n",
            "{'epoch': 1, 'batch': 45, 'loss': 7.06790018081665}\n",
            "{'epoch': 1, 'batch': 46, 'loss': 7.230766296386719}\n",
            "{'epoch': 1, 'batch': 47, 'loss': 7.507462501525879}\n",
            "{'epoch': 1, 'batch': 48, 'loss': 6.967891216278076}\n",
            "{'epoch': 1, 'batch': 49, 'loss': 7.218536853790283}\n",
            "{'epoch': 1, 'batch': 50, 'loss': 7.409040451049805}\n",
            "{'epoch': 1, 'batch': 51, 'loss': 7.2226080894470215}\n",
            "{'epoch': 1, 'batch': 52, 'loss': 6.844105243682861}\n",
            "{'epoch': 1, 'batch': 53, 'loss': 7.1337103843688965}\n",
            "{'epoch': 1, 'batch': 54, 'loss': 7.025221824645996}\n",
            "{'epoch': 1, 'batch': 55, 'loss': 7.071584224700928}\n",
            "{'epoch': 1, 'batch': 56, 'loss': 7.133892059326172}\n",
            "{'epoch': 1, 'batch': 57, 'loss': 7.135148048400879}\n",
            "{'epoch': 1, 'batch': 58, 'loss': 7.081065654754639}\n",
            "{'epoch': 1, 'batch': 59, 'loss': 7.124175071716309}\n",
            "{'epoch': 1, 'batch': 60, 'loss': 7.027434349060059}\n",
            "{'epoch': 1, 'batch': 61, 'loss': 7.190265655517578}\n",
            "{'epoch': 1, 'batch': 62, 'loss': 7.173516273498535}\n",
            "{'epoch': 1, 'batch': 63, 'loss': 7.104510307312012}\n",
            "{'epoch': 1, 'batch': 64, 'loss': 7.214298248291016}\n",
            "{'epoch': 1, 'batch': 65, 'loss': 7.139744758605957}\n",
            "{'epoch': 1, 'batch': 66, 'loss': 7.136228084564209}\n",
            "{'epoch': 1, 'batch': 67, 'loss': 6.94202184677124}\n",
            "{'epoch': 1, 'batch': 68, 'loss': 7.154202461242676}\n",
            "{'epoch': 1, 'batch': 69, 'loss': 6.89625883102417}\n",
            "{'epoch': 1, 'batch': 70, 'loss': 7.327419757843018}\n",
            "{'epoch': 1, 'batch': 71, 'loss': 7.2596435546875}\n",
            "{'epoch': 1, 'batch': 72, 'loss': 7.175684928894043}\n",
            "{'epoch': 1, 'batch': 73, 'loss': 7.250677108764648}\n",
            "{'epoch': 1, 'batch': 74, 'loss': 7.253452301025391}\n",
            "{'epoch': 1, 'batch': 75, 'loss': 7.389116287231445}\n",
            "{'epoch': 1, 'batch': 76, 'loss': 7.150036811828613}\n",
            "{'epoch': 1, 'batch': 77, 'loss': 7.417997360229492}\n",
            "{'epoch': 1, 'batch': 78, 'loss': 7.543181419372559}\n",
            "{'epoch': 1, 'batch': 79, 'loss': 6.8501105308532715}\n",
            "{'epoch': 1, 'batch': 80, 'loss': 7.131875514984131}\n",
            "{'epoch': 1, 'batch': 81, 'loss': 7.288758277893066}\n",
            "{'epoch': 1, 'batch': 82, 'loss': 7.292342185974121}\n",
            "{'epoch': 1, 'batch': 83, 'loss': 7.34618616104126}\n",
            "{'epoch': 1, 'batch': 84, 'loss': 7.167057037353516}\n",
            "{'epoch': 1, 'batch': 85, 'loss': 7.3517746925354}\n",
            "{'epoch': 1, 'batch': 86, 'loss': 7.09744930267334}\n",
            "{'epoch': 1, 'batch': 87, 'loss': 7.217073440551758}\n",
            "{'epoch': 1, 'batch': 88, 'loss': 7.099982261657715}\n",
            "{'epoch': 1, 'batch': 89, 'loss': 7.226310729980469}\n",
            "{'epoch': 1, 'batch': 90, 'loss': 7.577521800994873}\n",
            "{'epoch': 1, 'batch': 91, 'loss': 7.090063095092773}\n",
            "{'epoch': 1, 'batch': 92, 'loss': 7.3127031326293945}\n",
            "{'epoch': 1, 'batch': 93, 'loss': 6.892704963684082}\n",
            "{'epoch': 2, 'batch': 0, 'loss': 7.095284461975098}\n",
            "{'epoch': 2, 'batch': 1, 'loss': 7.083406925201416}\n",
            "{'epoch': 2, 'batch': 2, 'loss': 7.028721332550049}\n",
            "{'epoch': 2, 'batch': 3, 'loss': 7.250663757324219}\n",
            "{'epoch': 2, 'batch': 4, 'loss': 7.196568489074707}\n",
            "{'epoch': 2, 'batch': 5, 'loss': 7.2062249183654785}\n",
            "{'epoch': 2, 'batch': 6, 'loss': 7.5716657638549805}\n",
            "{'epoch': 2, 'batch': 7, 'loss': 7.399797439575195}\n",
            "{'epoch': 2, 'batch': 8, 'loss': 7.327414035797119}\n",
            "{'epoch': 2, 'batch': 9, 'loss': 7.181859016418457}\n",
            "{'epoch': 2, 'batch': 10, 'loss': 7.145130157470703}\n",
            "{'epoch': 2, 'batch': 11, 'loss': 7.085560321807861}\n",
            "{'epoch': 2, 'batch': 12, 'loss': 7.141878128051758}\n",
            "{'epoch': 2, 'batch': 13, 'loss': 7.232048988342285}\n",
            "{'epoch': 2, 'batch': 14, 'loss': 6.909193515777588}\n",
            "{'epoch': 2, 'batch': 15, 'loss': 7.005214691162109}\n",
            "{'epoch': 2, 'batch': 16, 'loss': 6.782120704650879}\n",
            "{'epoch': 2, 'batch': 17, 'loss': 6.995947360992432}\n",
            "{'epoch': 2, 'batch': 18, 'loss': 6.891448974609375}\n",
            "{'epoch': 2, 'batch': 19, 'loss': 7.002832889556885}\n",
            "{'epoch': 2, 'batch': 20, 'loss': 6.71797513961792}\n",
            "{'epoch': 2, 'batch': 21, 'loss': 7.122973918914795}\n",
            "{'epoch': 2, 'batch': 22, 'loss': 7.077361106872559}\n",
            "{'epoch': 2, 'batch': 23, 'loss': 7.173140525817871}\n",
            "{'epoch': 2, 'batch': 24, 'loss': 7.139163017272949}\n",
            "{'epoch': 2, 'batch': 25, 'loss': 6.868884563446045}\n",
            "{'epoch': 2, 'batch': 26, 'loss': 6.861900806427002}\n",
            "{'epoch': 2, 'batch': 27, 'loss': 6.86171817779541}\n",
            "{'epoch': 2, 'batch': 28, 'loss': 7.258103847503662}\n",
            "{'epoch': 2, 'batch': 29, 'loss': 7.366759300231934}\n",
            "{'epoch': 2, 'batch': 30, 'loss': 6.7188005447387695}\n",
            "{'epoch': 2, 'batch': 31, 'loss': 6.67375373840332}\n",
            "{'epoch': 2, 'batch': 32, 'loss': 6.817540168762207}\n",
            "{'epoch': 2, 'batch': 33, 'loss': 7.000890254974365}\n",
            "{'epoch': 2, 'batch': 34, 'loss': 6.936702728271484}\n",
            "{'epoch': 2, 'batch': 35, 'loss': 7.219549179077148}\n",
            "{'epoch': 2, 'batch': 36, 'loss': 7.119633674621582}\n",
            "{'epoch': 2, 'batch': 37, 'loss': 6.920880317687988}\n",
            "{'epoch': 2, 'batch': 38, 'loss': 7.231236457824707}\n",
            "{'epoch': 2, 'batch': 39, 'loss': 7.050040245056152}\n",
            "{'epoch': 2, 'batch': 40, 'loss': 7.280084133148193}\n",
            "{'epoch': 2, 'batch': 41, 'loss': 6.995822429656982}\n",
            "{'epoch': 2, 'batch': 42, 'loss': 7.2412285804748535}\n",
            "{'epoch': 2, 'batch': 43, 'loss': 6.96148157119751}\n",
            "{'epoch': 2, 'batch': 44, 'loss': 6.883183002471924}\n",
            "{'epoch': 2, 'batch': 45, 'loss': 7.005573749542236}\n",
            "{'epoch': 2, 'batch': 46, 'loss': 7.18133544921875}\n",
            "{'epoch': 2, 'batch': 47, 'loss': 7.473747253417969}\n",
            "{'epoch': 2, 'batch': 48, 'loss': 6.907244682312012}\n",
            "{'epoch': 2, 'batch': 49, 'loss': 7.157804489135742}\n",
            "{'epoch': 2, 'batch': 50, 'loss': 7.3423590660095215}\n",
            "{'epoch': 2, 'batch': 51, 'loss': 7.185161113739014}\n",
            "{'epoch': 2, 'batch': 52, 'loss': 6.789804458618164}\n",
            "{'epoch': 2, 'batch': 53, 'loss': 7.075693607330322}\n",
            "{'epoch': 2, 'batch': 54, 'loss': 6.955246448516846}\n",
            "{'epoch': 2, 'batch': 55, 'loss': 7.007732391357422}\n",
            "{'epoch': 2, 'batch': 56, 'loss': 7.045596122741699}\n",
            "{'epoch': 2, 'batch': 57, 'loss': 7.012283802032471}\n",
            "{'epoch': 2, 'batch': 58, 'loss': 6.964280605316162}\n",
            "{'epoch': 2, 'batch': 59, 'loss': 7.039060592651367}\n",
            "{'epoch': 2, 'batch': 60, 'loss': 6.931785583496094}\n",
            "{'epoch': 2, 'batch': 61, 'loss': 7.107723712921143}\n",
            "{'epoch': 2, 'batch': 62, 'loss': 7.085188388824463}\n",
            "{'epoch': 2, 'batch': 63, 'loss': 6.998402118682861}\n",
            "{'epoch': 2, 'batch': 64, 'loss': 7.074356555938721}\n",
            "{'epoch': 2, 'batch': 65, 'loss': 6.9978132247924805}\n",
            "{'epoch': 2, 'batch': 66, 'loss': 6.995698928833008}\n",
            "{'epoch': 2, 'batch': 67, 'loss': 6.810252666473389}\n",
            "{'epoch': 2, 'batch': 68, 'loss': 7.029837608337402}\n",
            "{'epoch': 2, 'batch': 69, 'loss': 6.744501113891602}\n",
            "{'epoch': 2, 'batch': 70, 'loss': 7.220992565155029}\n",
            "{'epoch': 2, 'batch': 71, 'loss': 7.121033191680908}\n",
            "{'epoch': 2, 'batch': 72, 'loss': 7.05793571472168}\n",
            "{'epoch': 2, 'batch': 73, 'loss': 7.096104621887207}\n",
            "{'epoch': 2, 'batch': 74, 'loss': 7.1001296043396}\n",
            "{'epoch': 2, 'batch': 75, 'loss': 7.205342769622803}\n",
            "{'epoch': 2, 'batch': 76, 'loss': 7.034305572509766}\n",
            "{'epoch': 2, 'batch': 77, 'loss': 7.2865190505981445}\n",
            "{'epoch': 2, 'batch': 78, 'loss': 7.3669819831848145}\n",
            "{'epoch': 2, 'batch': 79, 'loss': 6.722321510314941}\n",
            "{'epoch': 2, 'batch': 80, 'loss': 6.931056499481201}\n",
            "{'epoch': 2, 'batch': 81, 'loss': 7.154444217681885}\n",
            "{'epoch': 2, 'batch': 82, 'loss': 7.1454339027404785}\n",
            "{'epoch': 2, 'batch': 83, 'loss': 7.207867622375488}\n",
            "{'epoch': 2, 'batch': 84, 'loss': 7.083616733551025}\n",
            "{'epoch': 2, 'batch': 85, 'loss': 7.231183052062988}\n",
            "{'epoch': 2, 'batch': 86, 'loss': 6.935874938964844}\n",
            "{'epoch': 2, 'batch': 87, 'loss': 7.0489182472229}\n",
            "{'epoch': 2, 'batch': 88, 'loss': 6.936978340148926}\n",
            "{'epoch': 2, 'batch': 89, 'loss': 7.034965991973877}\n",
            "{'epoch': 2, 'batch': 90, 'loss': 7.413204193115234}\n",
            "{'epoch': 2, 'batch': 91, 'loss': 6.907718658447266}\n",
            "{'epoch': 2, 'batch': 92, 'loss': 7.12521505355835}\n",
            "{'epoch': 2, 'batch': 93, 'loss': 6.69857931137085}\n",
            "{'epoch': 3, 'batch': 0, 'loss': 6.996100902557373}\n",
            "{'epoch': 3, 'batch': 1, 'loss': 6.944964408874512}\n",
            "{'epoch': 3, 'batch': 2, 'loss': 6.931788921356201}\n",
            "{'epoch': 3, 'batch': 3, 'loss': 7.145007133483887}\n",
            "{'epoch': 3, 'batch': 4, 'loss': 7.068775177001953}\n",
            "{'epoch': 3, 'batch': 5, 'loss': 7.045238018035889}\n",
            "{'epoch': 3, 'batch': 6, 'loss': 7.494081974029541}\n",
            "{'epoch': 3, 'batch': 7, 'loss': 7.299668312072754}\n",
            "{'epoch': 3, 'batch': 8, 'loss': 7.187709808349609}\n",
            "{'epoch': 3, 'batch': 9, 'loss': 7.135416507720947}\n",
            "{'epoch': 3, 'batch': 10, 'loss': 7.108574390411377}\n",
            "{'epoch': 3, 'batch': 11, 'loss': 7.018560409545898}\n",
            "{'epoch': 3, 'batch': 12, 'loss': 7.0763421058654785}\n",
            "{'epoch': 3, 'batch': 13, 'loss': 7.1795334815979}\n",
            "{'epoch': 3, 'batch': 14, 'loss': 6.81218957901001}\n",
            "{'epoch': 3, 'batch': 15, 'loss': 6.943153381347656}\n",
            "{'epoch': 3, 'batch': 16, 'loss': 6.683687210083008}\n",
            "{'epoch': 3, 'batch': 17, 'loss': 6.901105880737305}\n",
            "{'epoch': 3, 'batch': 18, 'loss': 6.8175368309021}\n",
            "{'epoch': 3, 'batch': 19, 'loss': 6.919435977935791}\n",
            "{'epoch': 3, 'batch': 20, 'loss': 6.606131553649902}\n",
            "{'epoch': 3, 'batch': 21, 'loss': 7.048914432525635}\n",
            "{'epoch': 3, 'batch': 22, 'loss': 7.025692939758301}\n",
            "{'epoch': 3, 'batch': 23, 'loss': 7.080570220947266}\n",
            "{'epoch': 3, 'batch': 24, 'loss': 7.062228202819824}\n",
            "{'epoch': 3, 'batch': 25, 'loss': 6.7927021980285645}\n",
            "{'epoch': 3, 'batch': 26, 'loss': 6.762794017791748}\n",
            "{'epoch': 3, 'batch': 27, 'loss': 6.755836486816406}\n",
            "{'epoch': 3, 'batch': 28, 'loss': 7.174530982971191}\n",
            "{'epoch': 3, 'batch': 29, 'loss': 7.256026268005371}\n",
            "{'epoch': 3, 'batch': 30, 'loss': 6.611002445220947}\n",
            "{'epoch': 3, 'batch': 31, 'loss': 6.5513691902160645}\n",
            "{'epoch': 3, 'batch': 32, 'loss': 6.681340217590332}\n",
            "{'epoch': 3, 'batch': 33, 'loss': 6.909194469451904}\n",
            "{'epoch': 3, 'batch': 34, 'loss': 6.860416412353516}\n",
            "{'epoch': 3, 'batch': 35, 'loss': 7.088345050811768}\n",
            "{'epoch': 3, 'batch': 36, 'loss': 7.019251346588135}\n",
            "{'epoch': 3, 'batch': 37, 'loss': 6.832588195800781}\n",
            "{'epoch': 3, 'batch': 38, 'loss': 7.1285176277160645}\n",
            "{'epoch': 3, 'batch': 39, 'loss': 6.92555046081543}\n",
            "{'epoch': 3, 'batch': 40, 'loss': 7.147358417510986}\n",
            "{'epoch': 3, 'batch': 41, 'loss': 6.833079814910889}\n",
            "{'epoch': 3, 'batch': 42, 'loss': 7.121403694152832}\n",
            "{'epoch': 3, 'batch': 43, 'loss': 6.848388195037842}\n",
            "{'epoch': 3, 'batch': 44, 'loss': 6.792502403259277}\n",
            "{'epoch': 3, 'batch': 45, 'loss': 6.887734413146973}\n",
            "{'epoch': 3, 'batch': 46, 'loss': 7.0393218994140625}\n",
            "{'epoch': 3, 'batch': 47, 'loss': 7.392945289611816}\n",
            "{'epoch': 3, 'batch': 48, 'loss': 6.7301740646362305}\n",
            "{'epoch': 3, 'batch': 49, 'loss': 7.060647487640381}\n",
            "{'epoch': 3, 'batch': 50, 'loss': 7.2212114334106445}\n",
            "{'epoch': 3, 'batch': 51, 'loss': 7.116875648498535}\n",
            "{'epoch': 3, 'batch': 52, 'loss': 6.619101047515869}\n",
            "{'epoch': 3, 'batch': 53, 'loss': 6.990340709686279}\n",
            "{'epoch': 3, 'batch': 54, 'loss': 6.832559108734131}\n",
            "{'epoch': 3, 'batch': 55, 'loss': 6.905732154846191}\n",
            "{'epoch': 3, 'batch': 56, 'loss': 6.910284519195557}\n",
            "{'epoch': 3, 'batch': 57, 'loss': 6.868808269500732}\n",
            "{'epoch': 3, 'batch': 58, 'loss': 6.824297904968262}\n",
            "{'epoch': 3, 'batch': 59, 'loss': 6.929686069488525}\n",
            "{'epoch': 3, 'batch': 60, 'loss': 6.79583215713501}\n",
            "{'epoch': 3, 'batch': 61, 'loss': 6.990773677825928}\n",
            "{'epoch': 3, 'batch': 62, 'loss': 6.96077823638916}\n",
            "{'epoch': 3, 'batch': 63, 'loss': 6.907150745391846}\n",
            "{'epoch': 3, 'batch': 64, 'loss': 6.936689376831055}\n",
            "{'epoch': 3, 'batch': 65, 'loss': 6.886504650115967}\n",
            "{'epoch': 3, 'batch': 66, 'loss': 6.882114410400391}\n",
            "{'epoch': 3, 'batch': 67, 'loss': 6.678710460662842}\n",
            "{'epoch': 3, 'batch': 68, 'loss': 6.908390045166016}\n",
            "{'epoch': 3, 'batch': 69, 'loss': 6.624544143676758}\n",
            "{'epoch': 3, 'batch': 70, 'loss': 7.1176934242248535}\n",
            "{'epoch': 3, 'batch': 71, 'loss': 6.9768548011779785}\n",
            "{'epoch': 3, 'batch': 72, 'loss': 6.941476345062256}\n",
            "{'epoch': 3, 'batch': 73, 'loss': 6.984755992889404}\n",
            "{'epoch': 3, 'batch': 74, 'loss': 6.973611354827881}\n",
            "{'epoch': 3, 'batch': 75, 'loss': 7.050982475280762}\n",
            "{'epoch': 3, 'batch': 76, 'loss': 6.905416011810303}\n",
            "{'epoch': 3, 'batch': 77, 'loss': 7.185935974121094}\n",
            "{'epoch': 3, 'batch': 78, 'loss': 7.219032287597656}\n",
            "{'epoch': 3, 'batch': 79, 'loss': 6.606570720672607}\n",
            "{'epoch': 3, 'batch': 80, 'loss': 6.7946391105651855}\n",
            "{'epoch': 3, 'batch': 81, 'loss': 7.011966228485107}\n",
            "{'epoch': 3, 'batch': 82, 'loss': 6.980020046234131}\n",
            "{'epoch': 3, 'batch': 83, 'loss': 7.0672783851623535}\n",
            "{'epoch': 3, 'batch': 84, 'loss': 6.9547038078308105}\n",
            "{'epoch': 3, 'batch': 85, 'loss': 7.113796710968018}\n",
            "{'epoch': 3, 'batch': 86, 'loss': 6.814429759979248}\n",
            "{'epoch': 3, 'batch': 87, 'loss': 6.9139533042907715}\n",
            "{'epoch': 3, 'batch': 88, 'loss': 6.797647476196289}\n",
            "{'epoch': 3, 'batch': 89, 'loss': 6.876500606536865}\n",
            "{'epoch': 3, 'batch': 90, 'loss': 7.284492015838623}\n",
            "{'epoch': 3, 'batch': 91, 'loss': 6.7674407958984375}\n",
            "{'epoch': 3, 'batch': 92, 'loss': 7.032705307006836}\n",
            "{'epoch': 3, 'batch': 93, 'loss': 6.515979766845703}\n",
            "{'epoch': 4, 'batch': 0, 'loss': 6.880428314208984}\n",
            "{'epoch': 4, 'batch': 1, 'loss': 6.850433826446533}\n",
            "{'epoch': 4, 'batch': 2, 'loss': 6.838940143585205}\n",
            "{'epoch': 4, 'batch': 3, 'loss': 7.011648178100586}\n",
            "{'epoch': 4, 'batch': 4, 'loss': 6.943830966949463}\n",
            "{'epoch': 4, 'batch': 5, 'loss': 6.903005599975586}\n",
            "{'epoch': 4, 'batch': 6, 'loss': 7.404734134674072}\n",
            "{'epoch': 4, 'batch': 7, 'loss': 7.1870269775390625}\n",
            "{'epoch': 4, 'batch': 8, 'loss': 7.082937240600586}\n",
            "{'epoch': 4, 'batch': 9, 'loss': 7.042438507080078}\n",
            "{'epoch': 4, 'batch': 10, 'loss': 7.036013603210449}\n",
            "{'epoch': 4, 'batch': 11, 'loss': 6.907154560089111}\n",
            "{'epoch': 4, 'batch': 12, 'loss': 6.994948387145996}\n",
            "{'epoch': 4, 'batch': 13, 'loss': 7.122472286224365}\n",
            "{'epoch': 4, 'batch': 14, 'loss': 6.719367980957031}\n",
            "{'epoch': 4, 'batch': 15, 'loss': 6.8624162673950195}\n",
            "{'epoch': 4, 'batch': 16, 'loss': 6.604220867156982}\n",
            "{'epoch': 4, 'batch': 17, 'loss': 6.779533386230469}\n",
            "{'epoch': 4, 'batch': 18, 'loss': 6.7296953201293945}\n",
            "{'epoch': 4, 'batch': 19, 'loss': 6.831148624420166}\n",
            "{'epoch': 4, 'batch': 20, 'loss': 6.510133266448975}\n",
            "{'epoch': 4, 'batch': 21, 'loss': 6.960297107696533}\n",
            "{'epoch': 4, 'batch': 22, 'loss': 6.950289249420166}\n",
            "{'epoch': 4, 'batch': 23, 'loss': 7.016613960266113}\n",
            "{'epoch': 4, 'batch': 24, 'loss': 6.993240833282471}\n",
            "{'epoch': 4, 'batch': 25, 'loss': 6.720273971557617}\n",
            "{'epoch': 4, 'batch': 26, 'loss': 6.648349761962891}\n",
            "{'epoch': 4, 'batch': 27, 'loss': 6.64089822769165}\n",
            "{'epoch': 4, 'batch': 28, 'loss': 7.095590591430664}\n",
            "{'epoch': 4, 'batch': 29, 'loss': 7.1577935218811035}\n",
            "{'epoch': 4, 'batch': 30, 'loss': 6.503633975982666}\n",
            "{'epoch': 4, 'batch': 31, 'loss': 6.439877033233643}\n",
            "{'epoch': 4, 'batch': 32, 'loss': 6.554521083831787}\n",
            "{'epoch': 4, 'batch': 33, 'loss': 6.803084373474121}\n",
            "{'epoch': 4, 'batch': 34, 'loss': 6.754969120025635}\n",
            "{'epoch': 4, 'batch': 35, 'loss': 6.94334602355957}\n",
            "{'epoch': 4, 'batch': 36, 'loss': 6.886999130249023}\n",
            "{'epoch': 4, 'batch': 37, 'loss': 6.702773571014404}\n",
            "{'epoch': 4, 'batch': 38, 'loss': 7.0075483322143555}\n",
            "{'epoch': 4, 'batch': 39, 'loss': 6.799867630004883}\n",
            "{'epoch': 4, 'batch': 40, 'loss': 7.021647930145264}\n",
            "{'epoch': 4, 'batch': 41, 'loss': 6.686484336853027}\n",
            "{'epoch': 4, 'batch': 42, 'loss': 7.0028977394104}\n",
            "{'epoch': 4, 'batch': 43, 'loss': 6.725749969482422}\n",
            "{'epoch': 4, 'batch': 44, 'loss': 6.686083793640137}\n",
            "{'epoch': 4, 'batch': 45, 'loss': 6.758686065673828}\n",
            "{'epoch': 4, 'batch': 46, 'loss': 6.907212734222412}\n",
            "{'epoch': 4, 'batch': 47, 'loss': 7.271792888641357}\n",
            "{'epoch': 4, 'batch': 48, 'loss': 6.569239616394043}\n",
            "{'epoch': 4, 'batch': 49, 'loss': 6.951840400695801}\n",
            "{'epoch': 4, 'batch': 50, 'loss': 7.087343215942383}\n",
            "{'epoch': 4, 'batch': 51, 'loss': 7.016669273376465}\n",
            "{'epoch': 4, 'batch': 52, 'loss': 6.458023548126221}\n",
            "{'epoch': 4, 'batch': 53, 'loss': 6.849216938018799}\n",
            "{'epoch': 4, 'batch': 54, 'loss': 6.701706886291504}\n",
            "{'epoch': 4, 'batch': 55, 'loss': 6.7807440757751465}\n",
            "{'epoch': 4, 'batch': 56, 'loss': 6.794861793518066}\n",
            "{'epoch': 4, 'batch': 57, 'loss': 6.7582011222839355}\n",
            "{'epoch': 4, 'batch': 58, 'loss': 6.677719593048096}\n",
            "{'epoch': 4, 'batch': 59, 'loss': 6.8204145431518555}\n",
            "{'epoch': 4, 'batch': 60, 'loss': 6.664366245269775}\n",
            "{'epoch': 4, 'batch': 61, 'loss': 6.859744071960449}\n",
            "{'epoch': 4, 'batch': 62, 'loss': 6.838730335235596}\n",
            "{'epoch': 4, 'batch': 63, 'loss': 6.781761646270752}\n",
            "{'epoch': 4, 'batch': 64, 'loss': 6.775247573852539}\n",
            "{'epoch': 4, 'batch': 65, 'loss': 6.778832912445068}\n",
            "{'epoch': 4, 'batch': 66, 'loss': 6.753414630889893}\n",
            "{'epoch': 4, 'batch': 67, 'loss': 6.530113220214844}\n",
            "{'epoch': 4, 'batch': 68, 'loss': 6.763017654418945}\n",
            "{'epoch': 4, 'batch': 69, 'loss': 6.466662883758545}\n",
            "{'epoch': 4, 'batch': 70, 'loss': 6.999435901641846}\n",
            "{'epoch': 4, 'batch': 71, 'loss': 6.821924209594727}\n",
            "{'epoch': 4, 'batch': 72, 'loss': 6.769225597381592}\n",
            "{'epoch': 4, 'batch': 73, 'loss': 6.829306602478027}\n",
            "{'epoch': 4, 'batch': 74, 'loss': 6.8136982917785645}\n",
            "{'epoch': 4, 'batch': 75, 'loss': 6.873506546020508}\n",
            "{'epoch': 4, 'batch': 76, 'loss': 6.730584621429443}\n",
            "{'epoch': 4, 'batch': 77, 'loss': 7.038647651672363}\n",
            "{'epoch': 4, 'batch': 78, 'loss': 7.044276714324951}\n",
            "{'epoch': 4, 'batch': 79, 'loss': 6.446816444396973}\n",
            "{'epoch': 4, 'batch': 80, 'loss': 6.626264572143555}\n",
            "{'epoch': 4, 'batch': 81, 'loss': 6.847379207611084}\n",
            "{'epoch': 4, 'batch': 82, 'loss': 6.805752277374268}\n",
            "{'epoch': 4, 'batch': 83, 'loss': 6.9170942306518555}\n",
            "{'epoch': 4, 'batch': 84, 'loss': 6.822140216827393}\n",
            "{'epoch': 4, 'batch': 85, 'loss': 6.949092388153076}\n",
            "{'epoch': 4, 'batch': 86, 'loss': 6.655275821685791}\n",
            "{'epoch': 4, 'batch': 87, 'loss': 6.754451274871826}\n",
            "{'epoch': 4, 'batch': 88, 'loss': 6.6323041915893555}\n",
            "{'epoch': 4, 'batch': 89, 'loss': 6.718759059906006}\n",
            "{'epoch': 4, 'batch': 90, 'loss': 7.162069797515869}\n",
            "{'epoch': 4, 'batch': 91, 'loss': 6.6140875816345215}\n",
            "{'epoch': 4, 'batch': 92, 'loss': 6.88571834564209}\n",
            "{'epoch': 4, 'batch': 93, 'loss': 6.292438507080078}\n",
            "{'epoch': 5, 'batch': 0, 'loss': 6.762111186981201}\n",
            "{'epoch': 5, 'batch': 1, 'loss': 6.688607215881348}\n",
            "{'epoch': 5, 'batch': 2, 'loss': 6.713248252868652}\n",
            "{'epoch': 5, 'batch': 3, 'loss': 6.85092306137085}\n",
            "{'epoch': 5, 'batch': 4, 'loss': 6.776798248291016}\n",
            "{'epoch': 5, 'batch': 5, 'loss': 6.753890514373779}\n",
            "{'epoch': 5, 'batch': 6, 'loss': 7.286935329437256}\n",
            "{'epoch': 5, 'batch': 7, 'loss': 7.040850639343262}\n",
            "{'epoch': 5, 'batch': 8, 'loss': 6.936593532562256}\n",
            "{'epoch': 5, 'batch': 9, 'loss': 6.929924964904785}\n",
            "{'epoch': 5, 'batch': 10, 'loss': 6.941481590270996}\n",
            "{'epoch': 5, 'batch': 11, 'loss': 6.763294696807861}\n",
            "{'epoch': 5, 'batch': 12, 'loss': 6.867107391357422}\n",
            "{'epoch': 5, 'batch': 13, 'loss': 7.037405967712402}\n",
            "{'epoch': 5, 'batch': 14, 'loss': 6.575906276702881}\n",
            "{'epoch': 5, 'batch': 15, 'loss': 6.737598896026611}\n",
            "{'epoch': 5, 'batch': 16, 'loss': 6.47970724105835}\n",
            "{'epoch': 5, 'batch': 17, 'loss': 6.623943328857422}\n",
            "{'epoch': 5, 'batch': 18, 'loss': 6.5727362632751465}\n",
            "{'epoch': 5, 'batch': 19, 'loss': 6.698356628417969}\n",
            "{'epoch': 5, 'batch': 20, 'loss': 6.345222473144531}\n",
            "{'epoch': 5, 'batch': 21, 'loss': 6.819186687469482}\n",
            "{'epoch': 5, 'batch': 22, 'loss': 6.82297420501709}\n",
            "{'epoch': 5, 'batch': 23, 'loss': 6.899173736572266}\n",
            "{'epoch': 5, 'batch': 24, 'loss': 6.869540691375732}\n",
            "{'epoch': 5, 'batch': 25, 'loss': 6.591646194458008}\n",
            "{'epoch': 5, 'batch': 26, 'loss': 6.448572635650635}\n",
            "{'epoch': 5, 'batch': 27, 'loss': 6.49181604385376}\n",
            "{'epoch': 5, 'batch': 28, 'loss': 6.9935832023620605}\n",
            "{'epoch': 5, 'batch': 29, 'loss': 7.0277252197265625}\n",
            "{'epoch': 5, 'batch': 30, 'loss': 6.3331074714660645}\n",
            "{'epoch': 5, 'batch': 31, 'loss': 6.262729167938232}\n",
            "{'epoch': 5, 'batch': 32, 'loss': 6.406955718994141}\n",
            "{'epoch': 5, 'batch': 33, 'loss': 6.684790134429932}\n",
            "{'epoch': 5, 'batch': 34, 'loss': 6.608410358428955}\n",
            "{'epoch': 5, 'batch': 35, 'loss': 6.776208400726318}\n",
            "{'epoch': 5, 'batch': 36, 'loss': 6.7226643562316895}\n",
            "{'epoch': 5, 'batch': 37, 'loss': 6.575723648071289}\n",
            "{'epoch': 5, 'batch': 38, 'loss': 6.896766185760498}\n",
            "{'epoch': 5, 'batch': 39, 'loss': 6.648051738739014}\n",
            "{'epoch': 5, 'batch': 40, 'loss': 6.8710784912109375}\n",
            "{'epoch': 5, 'batch': 41, 'loss': 6.5053887367248535}\n",
            "{'epoch': 5, 'batch': 42, 'loss': 6.866145133972168}\n",
            "{'epoch': 5, 'batch': 43, 'loss': 6.5739521980285645}\n",
            "{'epoch': 5, 'batch': 44, 'loss': 6.5158371925354}\n",
            "{'epoch': 5, 'batch': 45, 'loss': 6.5883469581604}\n",
            "{'epoch': 5, 'batch': 46, 'loss': 6.731313705444336}\n",
            "{'epoch': 5, 'batch': 47, 'loss': 7.102832317352295}\n",
            "{'epoch': 5, 'batch': 48, 'loss': 6.362086772918701}\n",
            "{'epoch': 5, 'batch': 49, 'loss': 6.773616313934326}\n",
            "{'epoch': 5, 'batch': 50, 'loss': 6.909113883972168}\n",
            "{'epoch': 5, 'batch': 51, 'loss': 6.863256454467773}\n",
            "{'epoch': 5, 'batch': 52, 'loss': 6.23413610458374}\n",
            "{'epoch': 5, 'batch': 53, 'loss': 6.646223068237305}\n",
            "{'epoch': 5, 'batch': 54, 'loss': 6.5168070793151855}\n",
            "{'epoch': 5, 'batch': 55, 'loss': 6.596683025360107}\n",
            "{'epoch': 5, 'batch': 56, 'loss': 6.624598503112793}\n",
            "{'epoch': 5, 'batch': 57, 'loss': 6.583589553833008}\n",
            "{'epoch': 5, 'batch': 58, 'loss': 6.496606826782227}\n",
            "{'epoch': 5, 'batch': 59, 'loss': 6.657095909118652}\n",
            "{'epoch': 5, 'batch': 60, 'loss': 6.523066997528076}\n",
            "{'epoch': 5, 'batch': 61, 'loss': 6.683072090148926}\n",
            "{'epoch': 5, 'batch': 62, 'loss': 6.708764553070068}\n",
            "{'epoch': 5, 'batch': 63, 'loss': 6.622564315795898}\n",
            "{'epoch': 5, 'batch': 64, 'loss': 6.608372688293457}\n",
            "{'epoch': 5, 'batch': 65, 'loss': 6.652945041656494}\n",
            "{'epoch': 5, 'batch': 66, 'loss': 6.636022090911865}\n",
            "{'epoch': 5, 'batch': 67, 'loss': 6.3936357498168945}\n",
            "{'epoch': 5, 'batch': 68, 'loss': 6.615182399749756}\n",
            "{'epoch': 5, 'batch': 69, 'loss': 6.306407451629639}\n",
            "{'epoch': 5, 'batch': 70, 'loss': 6.878925323486328}\n",
            "{'epoch': 5, 'batch': 71, 'loss': 6.6838788986206055}\n",
            "{'epoch': 5, 'batch': 72, 'loss': 6.601968765258789}\n",
            "{'epoch': 5, 'batch': 73, 'loss': 6.678328037261963}\n",
            "{'epoch': 5, 'batch': 74, 'loss': 6.682255268096924}\n",
            "{'epoch': 5, 'batch': 75, 'loss': 6.704379558563232}\n",
            "{'epoch': 5, 'batch': 76, 'loss': 6.587959289550781}\n",
            "{'epoch': 5, 'batch': 77, 'loss': 6.8849992752075195}\n",
            "{'epoch': 5, 'batch': 78, 'loss': 6.886396884918213}\n",
            "{'epoch': 5, 'batch': 79, 'loss': 6.300267696380615}\n",
            "{'epoch': 5, 'batch': 80, 'loss': 6.446260929107666}\n",
            "{'epoch': 5, 'batch': 81, 'loss': 6.692399024963379}\n",
            "{'epoch': 5, 'batch': 82, 'loss': 6.634400367736816}\n",
            "{'epoch': 5, 'batch': 83, 'loss': 6.773261070251465}\n",
            "{'epoch': 5, 'batch': 84, 'loss': 6.6761088371276855}\n",
            "{'epoch': 5, 'batch': 85, 'loss': 6.756440162658691}\n",
            "{'epoch': 5, 'batch': 86, 'loss': 6.483954906463623}\n",
            "{'epoch': 5, 'batch': 87, 'loss': 6.589012622833252}\n",
            "{'epoch': 5, 'batch': 88, 'loss': 6.463605880737305}\n",
            "{'epoch': 5, 'batch': 89, 'loss': 6.528448581695557}\n",
            "{'epoch': 5, 'batch': 90, 'loss': 7.006887435913086}\n",
            "{'epoch': 5, 'batch': 91, 'loss': 6.446143627166748}\n",
            "{'epoch': 5, 'batch': 92, 'loss': 6.702828884124756}\n",
            "{'epoch': 5, 'batch': 93, 'loss': 6.095632553100586}\n",
            "{'epoch': 6, 'batch': 0, 'loss': 6.640198707580566}\n",
            "{'epoch': 6, 'batch': 1, 'loss': 6.535480499267578}\n",
            "{'epoch': 6, 'batch': 2, 'loss': 6.571321964263916}\n",
            "{'epoch': 6, 'batch': 3, 'loss': 6.699468612670898}\n",
            "{'epoch': 6, 'batch': 4, 'loss': 6.613058567047119}\n",
            "{'epoch': 6, 'batch': 5, 'loss': 6.605930805206299}\n",
            "{'epoch': 6, 'batch': 6, 'loss': 7.170820236206055}\n",
            "{'epoch': 6, 'batch': 7, 'loss': 6.9000749588012695}\n",
            "{'epoch': 6, 'batch': 8, 'loss': 6.808133602142334}\n",
            "{'epoch': 6, 'batch': 9, 'loss': 6.792230606079102}\n",
            "{'epoch': 6, 'batch': 10, 'loss': 6.827402591705322}\n",
            "{'epoch': 6, 'batch': 11, 'loss': 6.606483459472656}\n",
            "{'epoch': 6, 'batch': 12, 'loss': 6.746762275695801}\n",
            "{'epoch': 6, 'batch': 13, 'loss': 6.926220893859863}\n",
            "{'epoch': 6, 'batch': 14, 'loss': 6.424741744995117}\n",
            "{'epoch': 6, 'batch': 15, 'loss': 6.611971855163574}\n",
            "{'epoch': 6, 'batch': 16, 'loss': 6.3708600997924805}\n",
            "{'epoch': 6, 'batch': 17, 'loss': 6.462098121643066}\n",
            "{'epoch': 6, 'batch': 18, 'loss': 6.424709796905518}\n",
            "{'epoch': 6, 'batch': 19, 'loss': 6.566575050354004}\n",
            "{'epoch': 6, 'batch': 20, 'loss': 6.1819353103637695}\n",
            "{'epoch': 6, 'batch': 21, 'loss': 6.701488494873047}\n",
            "{'epoch': 6, 'batch': 22, 'loss': 6.713379859924316}\n",
            "{'epoch': 6, 'batch': 23, 'loss': 6.796075344085693}\n",
            "{'epoch': 6, 'batch': 24, 'loss': 6.752927780151367}\n",
            "{'epoch': 6, 'batch': 25, 'loss': 6.479532241821289}\n",
            "{'epoch': 6, 'batch': 26, 'loss': 6.2834792137146}\n",
            "{'epoch': 6, 'batch': 27, 'loss': 6.365183353424072}\n",
            "{'epoch': 6, 'batch': 28, 'loss': 6.895497798919678}\n",
            "{'epoch': 6, 'batch': 29, 'loss': 6.928860664367676}\n",
            "{'epoch': 6, 'batch': 30, 'loss': 6.206059455871582}\n",
            "{'epoch': 6, 'batch': 31, 'loss': 6.13058614730835}\n",
            "{'epoch': 6, 'batch': 32, 'loss': 6.296001434326172}\n",
            "{'epoch': 6, 'batch': 33, 'loss': 6.577025413513184}\n",
            "{'epoch': 6, 'batch': 34, 'loss': 6.485264301300049}\n",
            "{'epoch': 6, 'batch': 35, 'loss': 6.644626617431641}\n",
            "{'epoch': 6, 'batch': 36, 'loss': 6.583652496337891}\n",
            "{'epoch': 6, 'batch': 37, 'loss': 6.5072245597839355}\n",
            "{'epoch': 6, 'batch': 38, 'loss': 6.820123195648193}\n",
            "{'epoch': 6, 'batch': 39, 'loss': 6.560480117797852}\n",
            "{'epoch': 6, 'batch': 40, 'loss': 6.770007610321045}\n",
            "{'epoch': 6, 'batch': 41, 'loss': 6.391948699951172}\n",
            "{'epoch': 6, 'batch': 42, 'loss': 6.758817195892334}\n",
            "{'epoch': 6, 'batch': 43, 'loss': 6.474939346313477}\n",
            "{'epoch': 6, 'batch': 44, 'loss': 6.4188032150268555}\n",
            "{'epoch': 6, 'batch': 45, 'loss': 6.519108295440674}\n",
            "{'epoch': 6, 'batch': 46, 'loss': 6.648373603820801}\n",
            "{'epoch': 6, 'batch': 47, 'loss': 7.017640590667725}\n",
            "{'epoch': 6, 'batch': 48, 'loss': 6.223226070404053}\n",
            "{'epoch': 6, 'batch': 49, 'loss': 6.645764350891113}\n",
            "{'epoch': 6, 'batch': 50, 'loss': 6.795952796936035}\n",
            "{'epoch': 6, 'batch': 51, 'loss': 6.777824401855469}\n",
            "{'epoch': 6, 'batch': 52, 'loss': 6.118381023406982}\n",
            "{'epoch': 6, 'batch': 53, 'loss': 6.4965925216674805}\n",
            "{'epoch': 6, 'batch': 54, 'loss': 6.409084796905518}\n",
            "{'epoch': 6, 'batch': 55, 'loss': 6.434607028961182}\n",
            "{'epoch': 6, 'batch': 56, 'loss': 6.522260665893555}\n",
            "{'epoch': 6, 'batch': 57, 'loss': 6.466318130493164}\n",
            "{'epoch': 6, 'batch': 58, 'loss': 6.335535526275635}\n",
            "{'epoch': 6, 'batch': 59, 'loss': 6.497189044952393}\n",
            "{'epoch': 6, 'batch': 60, 'loss': 6.400909423828125}\n",
            "{'epoch': 6, 'batch': 61, 'loss': 6.5213398933410645}\n",
            "{'epoch': 6, 'batch': 62, 'loss': 6.574386119842529}\n",
            "{'epoch': 6, 'batch': 63, 'loss': 6.468400478363037}\n",
            "{'epoch': 6, 'batch': 64, 'loss': 6.450787544250488}\n",
            "{'epoch': 6, 'batch': 65, 'loss': 6.5299506187438965}\n",
            "{'epoch': 6, 'batch': 66, 'loss': 6.527123928070068}\n",
            "{'epoch': 6, 'batch': 67, 'loss': 6.243919849395752}\n",
            "{'epoch': 6, 'batch': 68, 'loss': 6.461543083190918}\n",
            "{'epoch': 6, 'batch': 69, 'loss': 6.151257038116455}\n",
            "{'epoch': 6, 'batch': 70, 'loss': 6.721479892730713}\n",
            "{'epoch': 6, 'batch': 71, 'loss': 6.528362274169922}\n",
            "{'epoch': 6, 'batch': 72, 'loss': 6.480935096740723}\n",
            "{'epoch': 6, 'batch': 73, 'loss': 6.520370006561279}\n",
            "{'epoch': 6, 'batch': 74, 'loss': 6.537057876586914}\n",
            "{'epoch': 6, 'batch': 75, 'loss': 6.56635046005249}\n",
            "{'epoch': 6, 'batch': 76, 'loss': 6.455856800079346}\n",
            "{'epoch': 6, 'batch': 77, 'loss': 6.717512130737305}\n",
            "{'epoch': 6, 'batch': 78, 'loss': 6.762892723083496}\n",
            "{'epoch': 6, 'batch': 79, 'loss': 6.147132873535156}\n",
            "{'epoch': 6, 'batch': 80, 'loss': 6.300685882568359}\n",
            "{'epoch': 6, 'batch': 81, 'loss': 6.549228668212891}\n",
            "{'epoch': 6, 'batch': 82, 'loss': 6.477512836456299}\n",
            "{'epoch': 6, 'batch': 83, 'loss': 6.622203350067139}\n",
            "{'epoch': 6, 'batch': 84, 'loss': 6.524245738983154}\n",
            "{'epoch': 6, 'batch': 85, 'loss': 6.598661422729492}\n",
            "{'epoch': 6, 'batch': 86, 'loss': 6.317609786987305}\n",
            "{'epoch': 6, 'batch': 87, 'loss': 6.425492286682129}\n",
            "{'epoch': 6, 'batch': 88, 'loss': 6.3018083572387695}\n",
            "{'epoch': 6, 'batch': 89, 'loss': 6.384424209594727}\n",
            "{'epoch': 6, 'batch': 90, 'loss': 6.851457595825195}\n",
            "{'epoch': 6, 'batch': 91, 'loss': 6.270052909851074}\n",
            "{'epoch': 6, 'batch': 92, 'loss': 6.511437892913818}\n",
            "{'epoch': 6, 'batch': 93, 'loss': 5.89998722076416}\n",
            "{'epoch': 7, 'batch': 0, 'loss': 6.47011661529541}\n",
            "{'epoch': 7, 'batch': 1, 'loss': 6.351981163024902}\n",
            "{'epoch': 7, 'batch': 2, 'loss': 6.444403648376465}\n",
            "{'epoch': 7, 'batch': 3, 'loss': 6.524572372436523}\n",
            "{'epoch': 7, 'batch': 4, 'loss': 6.440329074859619}\n",
            "{'epoch': 7, 'batch': 5, 'loss': 6.440079689025879}\n",
            "{'epoch': 7, 'batch': 6, 'loss': 7.035478591918945}\n",
            "{'epoch': 7, 'batch': 7, 'loss': 6.747697353363037}\n",
            "{'epoch': 7, 'batch': 8, 'loss': 6.6604323387146}\n",
            "{'epoch': 7, 'batch': 9, 'loss': 6.622392654418945}\n",
            "{'epoch': 7, 'batch': 10, 'loss': 6.67479944229126}\n",
            "{'epoch': 7, 'batch': 11, 'loss': 6.447841167449951}\n",
            "{'epoch': 7, 'batch': 12, 'loss': 6.595767974853516}\n",
            "{'epoch': 7, 'batch': 13, 'loss': 6.796543121337891}\n",
            "{'epoch': 7, 'batch': 14, 'loss': 6.27216911315918}\n",
            "{'epoch': 7, 'batch': 15, 'loss': 6.468077182769775}\n",
            "{'epoch': 7, 'batch': 16, 'loss': 6.252172946929932}\n",
            "{'epoch': 7, 'batch': 17, 'loss': 6.337010860443115}\n",
            "{'epoch': 7, 'batch': 18, 'loss': 6.279806137084961}\n",
            "{'epoch': 7, 'batch': 19, 'loss': 6.445343971252441}\n",
            "{'epoch': 7, 'batch': 20, 'loss': 6.016977787017822}\n",
            "{'epoch': 7, 'batch': 21, 'loss': 6.5673089027404785}\n",
            "{'epoch': 7, 'batch': 22, 'loss': 6.583491325378418}\n",
            "{'epoch': 7, 'batch': 23, 'loss': 6.660126686096191}\n",
            "{'epoch': 7, 'batch': 24, 'loss': 6.586658954620361}\n",
            "{'epoch': 7, 'batch': 25, 'loss': 6.353453636169434}\n",
            "{'epoch': 7, 'batch': 26, 'loss': 6.1266655921936035}\n",
            "{'epoch': 7, 'batch': 27, 'loss': 6.224527835845947}\n",
            "{'epoch': 7, 'batch': 28, 'loss': 6.738419055938721}\n",
            "{'epoch': 7, 'batch': 29, 'loss': 6.7924699783325195}\n",
            "{'epoch': 7, 'batch': 30, 'loss': 6.045825004577637}\n",
            "{'epoch': 7, 'batch': 31, 'loss': 5.965303421020508}\n",
            "{'epoch': 7, 'batch': 32, 'loss': 6.150321006774902}\n",
            "{'epoch': 7, 'batch': 33, 'loss': 6.433307647705078}\n",
            "{'epoch': 7, 'batch': 34, 'loss': 6.306372165679932}\n",
            "{'epoch': 7, 'batch': 35, 'loss': 6.467123031616211}\n",
            "{'epoch': 7, 'batch': 36, 'loss': 6.394874572753906}\n",
            "{'epoch': 7, 'batch': 37, 'loss': 6.357487201690674}\n",
            "{'epoch': 7, 'batch': 38, 'loss': 6.686071395874023}\n",
            "{'epoch': 7, 'batch': 39, 'loss': 6.399621963500977}\n",
            "{'epoch': 7, 'batch': 40, 'loss': 6.604391098022461}\n",
            "{'epoch': 7, 'batch': 41, 'loss': 6.2286295890808105}\n",
            "{'epoch': 7, 'batch': 42, 'loss': 6.601016044616699}\n",
            "{'epoch': 7, 'batch': 43, 'loss': 6.309168815612793}\n",
            "{'epoch': 7, 'batch': 44, 'loss': 6.2141618728637695}\n",
            "{'epoch': 7, 'batch': 45, 'loss': 6.3788838386535645}\n",
            "{'epoch': 7, 'batch': 46, 'loss': 6.4768524169921875}\n",
            "{'epoch': 7, 'batch': 47, 'loss': 6.838908672332764}\n",
            "{'epoch': 7, 'batch': 48, 'loss': 6.050622463226318}\n",
            "{'epoch': 7, 'batch': 49, 'loss': 6.459754467010498}\n",
            "{'epoch': 7, 'batch': 50, 'loss': 6.620699405670166}\n",
            "{'epoch': 7, 'batch': 51, 'loss': 6.65658712387085}\n",
            "{'epoch': 7, 'batch': 52, 'loss': 5.951732635498047}\n",
            "{'epoch': 7, 'batch': 53, 'loss': 6.299098014831543}\n",
            "{'epoch': 7, 'batch': 54, 'loss': 6.244462966918945}\n",
            "{'epoch': 7, 'batch': 55, 'loss': 6.248854637145996}\n",
            "{'epoch': 7, 'batch': 56, 'loss': 6.333662033081055}\n",
            "{'epoch': 7, 'batch': 57, 'loss': 6.271071434020996}\n",
            "{'epoch': 7, 'batch': 58, 'loss': 6.1574249267578125}\n",
            "{'epoch': 7, 'batch': 59, 'loss': 6.286825656890869}\n",
            "{'epoch': 7, 'batch': 60, 'loss': 6.2209553718566895}\n",
            "{'epoch': 7, 'batch': 61, 'loss': 6.323328018188477}\n",
            "{'epoch': 7, 'batch': 62, 'loss': 6.393725395202637}\n",
            "{'epoch': 7, 'batch': 63, 'loss': 6.290471076965332}\n",
            "{'epoch': 7, 'batch': 64, 'loss': 6.273226737976074}\n",
            "{'epoch': 7, 'batch': 65, 'loss': 6.3666510581970215}\n",
            "{'epoch': 7, 'batch': 66, 'loss': 6.388256549835205}\n",
            "{'epoch': 7, 'batch': 67, 'loss': 6.071735382080078}\n",
            "{'epoch': 7, 'batch': 68, 'loss': 6.308956623077393}\n",
            "{'epoch': 7, 'batch': 69, 'loss': 5.981940269470215}\n",
            "{'epoch': 7, 'batch': 70, 'loss': 6.567173480987549}\n",
            "{'epoch': 7, 'batch': 71, 'loss': 6.376712322235107}\n",
            "{'epoch': 7, 'batch': 72, 'loss': 6.348184585571289}\n",
            "{'epoch': 7, 'batch': 73, 'loss': 6.355080604553223}\n",
            "{'epoch': 7, 'batch': 74, 'loss': 6.3939433097839355}\n",
            "{'epoch': 7, 'batch': 75, 'loss': 6.427280426025391}\n",
            "{'epoch': 7, 'batch': 76, 'loss': 6.314624309539795}\n",
            "{'epoch': 7, 'batch': 77, 'loss': 6.537032127380371}\n",
            "{'epoch': 7, 'batch': 78, 'loss': 6.631192207336426}\n",
            "{'epoch': 7, 'batch': 79, 'loss': 5.999019622802734}\n",
            "{'epoch': 7, 'batch': 80, 'loss': 6.139003753662109}\n",
            "{'epoch': 7, 'batch': 81, 'loss': 6.404019355773926}\n",
            "{'epoch': 7, 'batch': 82, 'loss': 6.334982872009277}\n",
            "{'epoch': 7, 'batch': 83, 'loss': 6.4803338050842285}\n",
            "{'epoch': 7, 'batch': 84, 'loss': 6.3676371574401855}\n",
            "{'epoch': 7, 'batch': 85, 'loss': 6.4304375648498535}\n",
            "{'epoch': 7, 'batch': 86, 'loss': 6.174454689025879}\n",
            "{'epoch': 7, 'batch': 87, 'loss': 6.293485641479492}\n",
            "{'epoch': 7, 'batch': 88, 'loss': 6.165462493896484}\n",
            "{'epoch': 7, 'batch': 89, 'loss': 6.247686862945557}\n",
            "{'epoch': 7, 'batch': 90, 'loss': 6.702579975128174}\n",
            "{'epoch': 7, 'batch': 91, 'loss': 6.124305725097656}\n",
            "{'epoch': 7, 'batch': 92, 'loss': 6.341712951660156}\n",
            "{'epoch': 7, 'batch': 93, 'loss': 5.756784915924072}\n",
            "{'epoch': 8, 'batch': 0, 'loss': 6.311474800109863}\n",
            "{'epoch': 8, 'batch': 1, 'loss': 6.190944194793701}\n",
            "{'epoch': 8, 'batch': 2, 'loss': 6.313830375671387}\n",
            "{'epoch': 8, 'batch': 3, 'loss': 6.378743648529053}\n",
            "{'epoch': 8, 'batch': 4, 'loss': 6.263380527496338}\n",
            "{'epoch': 8, 'batch': 5, 'loss': 6.2990593910217285}\n",
            "{'epoch': 8, 'batch': 6, 'loss': 6.8891191482543945}\n",
            "{'epoch': 8, 'batch': 7, 'loss': 6.580892086029053}\n",
            "{'epoch': 8, 'batch': 8, 'loss': 6.518499374389648}\n",
            "{'epoch': 8, 'batch': 9, 'loss': 6.468459129333496}\n",
            "{'epoch': 8, 'batch': 10, 'loss': 6.554646015167236}\n",
            "{'epoch': 8, 'batch': 11, 'loss': 6.304066181182861}\n",
            "{'epoch': 8, 'batch': 12, 'loss': 6.446198463439941}\n",
            "{'epoch': 8, 'batch': 13, 'loss': 6.637759208679199}\n",
            "{'epoch': 8, 'batch': 14, 'loss': 6.121001720428467}\n",
            "{'epoch': 8, 'batch': 15, 'loss': 6.326155185699463}\n",
            "{'epoch': 8, 'batch': 16, 'loss': 6.109782695770264}\n",
            "{'epoch': 8, 'batch': 17, 'loss': 6.168787002563477}\n",
            "{'epoch': 8, 'batch': 18, 'loss': 6.164885997772217}\n",
            "{'epoch': 8, 'batch': 19, 'loss': 6.311047554016113}\n",
            "{'epoch': 8, 'batch': 20, 'loss': 5.841244697570801}\n",
            "{'epoch': 8, 'batch': 21, 'loss': 6.414249897003174}\n",
            "{'epoch': 8, 'batch': 22, 'loss': 6.435790538787842}\n",
            "{'epoch': 8, 'batch': 23, 'loss': 6.525229454040527}\n",
            "{'epoch': 8, 'batch': 24, 'loss': 6.43141508102417}\n",
            "{'epoch': 8, 'batch': 25, 'loss': 6.2129364013671875}\n",
            "{'epoch': 8, 'batch': 26, 'loss': 5.962048530578613}\n",
            "{'epoch': 8, 'batch': 27, 'loss': 6.075741767883301}\n",
            "{'epoch': 8, 'batch': 28, 'loss': 6.585760593414307}\n",
            "{'epoch': 8, 'batch': 29, 'loss': 6.646961212158203}\n",
            "{'epoch': 8, 'batch': 30, 'loss': 5.893615245819092}\n",
            "{'epoch': 8, 'batch': 31, 'loss': 5.799519062042236}\n",
            "{'epoch': 8, 'batch': 32, 'loss': 5.9883527755737305}\n",
            "{'epoch': 8, 'batch': 33, 'loss': 6.281264781951904}\n",
            "{'epoch': 8, 'batch': 34, 'loss': 6.147638320922852}\n",
            "{'epoch': 8, 'batch': 35, 'loss': 6.309811592102051}\n",
            "{'epoch': 8, 'batch': 36, 'loss': 6.223362445831299}\n",
            "{'epoch': 8, 'batch': 37, 'loss': 6.2005720138549805}\n",
            "{'epoch': 8, 'batch': 38, 'loss': 6.522266387939453}\n",
            "{'epoch': 8, 'batch': 39, 'loss': 6.2525482177734375}\n",
            "{'epoch': 8, 'batch': 40, 'loss': 6.424942493438721}\n",
            "{'epoch': 8, 'batch': 41, 'loss': 6.052528381347656}\n",
            "{'epoch': 8, 'batch': 42, 'loss': 6.446417331695557}\n",
            "{'epoch': 8, 'batch': 43, 'loss': 6.138690948486328}\n",
            "{'epoch': 8, 'batch': 44, 'loss': 6.045918941497803}\n",
            "{'epoch': 8, 'batch': 45, 'loss': 6.244467258453369}\n",
            "{'epoch': 8, 'batch': 46, 'loss': 6.335882663726807}\n",
            "{'epoch': 8, 'batch': 47, 'loss': 6.703061580657959}\n",
            "{'epoch': 8, 'batch': 48, 'loss': 5.883810520172119}\n",
            "{'epoch': 8, 'batch': 49, 'loss': 6.288026809692383}\n",
            "{'epoch': 8, 'batch': 50, 'loss': 6.467601776123047}\n",
            "{'epoch': 8, 'batch': 51, 'loss': 6.510464668273926}\n",
            "{'epoch': 8, 'batch': 52, 'loss': 5.821150302886963}\n",
            "{'epoch': 8, 'batch': 53, 'loss': 6.119111061096191}\n",
            "{'epoch': 8, 'batch': 54, 'loss': 6.1215715408325195}\n",
            "{'epoch': 8, 'batch': 55, 'loss': 6.119714260101318}\n",
            "{'epoch': 8, 'batch': 56, 'loss': 6.189155578613281}\n",
            "{'epoch': 8, 'batch': 57, 'loss': 6.132249355316162}\n",
            "{'epoch': 8, 'batch': 58, 'loss': 6.039680004119873}\n",
            "{'epoch': 8, 'batch': 59, 'loss': 6.125932693481445}\n",
            "{'epoch': 8, 'batch': 60, 'loss': 6.076509475708008}\n",
            "{'epoch': 8, 'batch': 61, 'loss': 6.169422149658203}\n",
            "{'epoch': 8, 'batch': 62, 'loss': 6.2426981925964355}\n",
            "{'epoch': 8, 'batch': 63, 'loss': 6.132856845855713}\n",
            "{'epoch': 8, 'batch': 64, 'loss': 6.119903564453125}\n",
            "{'epoch': 8, 'batch': 65, 'loss': 6.202215671539307}\n",
            "{'epoch': 8, 'batch': 66, 'loss': 6.235799789428711}\n",
            "{'epoch': 8, 'batch': 67, 'loss': 5.873712539672852}\n",
            "{'epoch': 8, 'batch': 68, 'loss': 6.166868686676025}\n",
            "{'epoch': 8, 'batch': 69, 'loss': 5.8181304931640625}\n",
            "{'epoch': 8, 'batch': 70, 'loss': 6.437290668487549}\n",
            "{'epoch': 8, 'batch': 71, 'loss': 6.227137565612793}\n",
            "{'epoch': 8, 'batch': 72, 'loss': 6.213442325592041}\n",
            "{'epoch': 8, 'batch': 73, 'loss': 6.216302871704102}\n",
            "{'epoch': 8, 'batch': 74, 'loss': 6.245872974395752}\n",
            "{'epoch': 8, 'batch': 75, 'loss': 6.266451835632324}\n",
            "{'epoch': 8, 'batch': 76, 'loss': 6.153244495391846}\n",
            "{'epoch': 8, 'batch': 77, 'loss': 6.383814334869385}\n",
            "{'epoch': 8, 'batch': 78, 'loss': 6.466596603393555}\n",
            "{'epoch': 8, 'batch': 79, 'loss': 5.822169780731201}\n",
            "{'epoch': 8, 'batch': 80, 'loss': 5.9821553230285645}\n",
            "{'epoch': 8, 'batch': 81, 'loss': 6.2480549812316895}\n",
            "{'epoch': 8, 'batch': 82, 'loss': 6.188783645629883}\n",
            "{'epoch': 8, 'batch': 83, 'loss': 6.3334574699401855}\n",
            "{'epoch': 8, 'batch': 84, 'loss': 6.22606086730957}\n",
            "{'epoch': 8, 'batch': 85, 'loss': 6.277568817138672}\n",
            "{'epoch': 8, 'batch': 86, 'loss': 6.018467426300049}\n",
            "{'epoch': 8, 'batch': 87, 'loss': 6.142140865325928}\n",
            "{'epoch': 8, 'batch': 88, 'loss': 6.00965690612793}\n",
            "{'epoch': 8, 'batch': 89, 'loss': 6.115544319152832}\n",
            "{'epoch': 8, 'batch': 90, 'loss': 6.549210548400879}\n",
            "{'epoch': 8, 'batch': 91, 'loss': 5.969832420349121}\n",
            "{'epoch': 8, 'batch': 92, 'loss': 6.183398723602295}\n",
            "{'epoch': 8, 'batch': 93, 'loss': 5.579251766204834}\n",
            "{'epoch': 9, 'batch': 0, 'loss': 6.134321212768555}\n",
            "{'epoch': 9, 'batch': 1, 'loss': 6.027599811553955}\n",
            "{'epoch': 9, 'batch': 2, 'loss': 6.14332914352417}\n",
            "{'epoch': 9, 'batch': 3, 'loss': 6.258492946624756}\n",
            "{'epoch': 9, 'batch': 4, 'loss': 6.0948920249938965}\n",
            "{'epoch': 9, 'batch': 5, 'loss': 6.150857448577881}\n",
            "{'epoch': 9, 'batch': 6, 'loss': 6.74803352355957}\n",
            "{'epoch': 9, 'batch': 7, 'loss': 6.445199012756348}\n",
            "{'epoch': 9, 'batch': 8, 'loss': 6.37162971496582}\n",
            "{'epoch': 9, 'batch': 9, 'loss': 6.309074401855469}\n",
            "{'epoch': 9, 'batch': 10, 'loss': 6.410295486450195}\n",
            "{'epoch': 9, 'batch': 11, 'loss': 6.154847145080566}\n",
            "{'epoch': 9, 'batch': 12, 'loss': 6.315906524658203}\n",
            "{'epoch': 9, 'batch': 13, 'loss': 6.496837615966797}\n",
            "{'epoch': 9, 'batch': 14, 'loss': 5.985712051391602}\n",
            "{'epoch': 9, 'batch': 15, 'loss': 6.1844635009765625}\n",
            "{'epoch': 9, 'batch': 16, 'loss': 5.946062088012695}\n",
            "{'epoch': 9, 'batch': 17, 'loss': 6.022866725921631}\n",
            "{'epoch': 9, 'batch': 18, 'loss': 6.005836486816406}\n",
            "{'epoch': 9, 'batch': 19, 'loss': 6.174083232879639}\n",
            "{'epoch': 9, 'batch': 20, 'loss': 5.680509567260742}\n",
            "{'epoch': 9, 'batch': 21, 'loss': 6.260889530181885}\n",
            "{'epoch': 9, 'batch': 22, 'loss': 6.289597034454346}\n",
            "{'epoch': 9, 'batch': 23, 'loss': 6.389369487762451}\n",
            "{'epoch': 9, 'batch': 24, 'loss': 6.280685901641846}\n",
            "{'epoch': 9, 'batch': 25, 'loss': 6.081441879272461}\n",
            "{'epoch': 9, 'batch': 26, 'loss': 5.815769195556641}\n",
            "{'epoch': 9, 'batch': 27, 'loss': 5.9197492599487305}\n",
            "{'epoch': 9, 'batch': 28, 'loss': 6.419345378875732}\n",
            "{'epoch': 9, 'batch': 29, 'loss': 6.507133483886719}\n",
            "{'epoch': 9, 'batch': 30, 'loss': 5.724742889404297}\n",
            "{'epoch': 9, 'batch': 31, 'loss': 5.648963451385498}\n",
            "{'epoch': 9, 'batch': 32, 'loss': 5.868486404418945}\n",
            "{'epoch': 9, 'batch': 33, 'loss': 6.126794815063477}\n",
            "{'epoch': 9, 'batch': 34, 'loss': 5.986016273498535}\n",
            "{'epoch': 9, 'batch': 35, 'loss': 6.13484001159668}\n",
            "{'epoch': 9, 'batch': 36, 'loss': 6.071290969848633}\n",
            "{'epoch': 9, 'batch': 37, 'loss': 6.0457658767700195}\n",
            "{'epoch': 9, 'batch': 38, 'loss': 6.38701868057251}\n",
            "{'epoch': 9, 'batch': 39, 'loss': 6.102046966552734}\n",
            "{'epoch': 9, 'batch': 40, 'loss': 6.250331878662109}\n",
            "{'epoch': 9, 'batch': 41, 'loss': 5.88856840133667}\n",
            "{'epoch': 9, 'batch': 42, 'loss': 6.313780784606934}\n",
            "{'epoch': 9, 'batch': 43, 'loss': 5.971677780151367}\n",
            "{'epoch': 9, 'batch': 44, 'loss': 5.8933892250061035}\n",
            "{'epoch': 9, 'batch': 45, 'loss': 6.083305358886719}\n",
            "{'epoch': 9, 'batch': 46, 'loss': 6.1743855476379395}\n",
            "{'epoch': 9, 'batch': 47, 'loss': 6.561995506286621}\n",
            "{'epoch': 9, 'batch': 48, 'loss': 5.730288505554199}\n",
            "{'epoch': 9, 'batch': 49, 'loss': 6.123756408691406}\n",
            "{'epoch': 9, 'batch': 50, 'loss': 6.3303914070129395}\n",
            "{'epoch': 9, 'batch': 51, 'loss': 6.36976432800293}\n",
            "{'epoch': 9, 'batch': 52, 'loss': 5.704794406890869}\n",
            "{'epoch': 9, 'batch': 53, 'loss': 5.963110446929932}\n",
            "{'epoch': 9, 'batch': 54, 'loss': 5.956425666809082}\n",
            "{'epoch': 9, 'batch': 55, 'loss': 5.969224452972412}\n",
            "{'epoch': 9, 'batch': 56, 'loss': 6.046916961669922}\n",
            "{'epoch': 9, 'batch': 57, 'loss': 5.985162734985352}\n",
            "{'epoch': 9, 'batch': 58, 'loss': 5.928186893463135}\n",
            "{'epoch': 9, 'batch': 59, 'loss': 5.972660541534424}\n",
            "{'epoch': 9, 'batch': 60, 'loss': 5.945552349090576}\n",
            "{'epoch': 9, 'batch': 61, 'loss': 6.025143146514893}\n",
            "{'epoch': 9, 'batch': 62, 'loss': 6.07762336730957}\n",
            "{'epoch': 9, 'batch': 63, 'loss': 5.992974281311035}\n",
            "{'epoch': 9, 'batch': 64, 'loss': 5.984358310699463}\n",
            "{'epoch': 9, 'batch': 65, 'loss': 6.055799961090088}\n",
            "{'epoch': 9, 'batch': 66, 'loss': 6.090058326721191}\n",
            "{'epoch': 9, 'batch': 67, 'loss': 5.727588653564453}\n",
            "{'epoch': 9, 'batch': 68, 'loss': 5.999798774719238}\n",
            "{'epoch': 9, 'batch': 69, 'loss': 5.68655252456665}\n",
            "{'epoch': 9, 'batch': 70, 'loss': 6.3014984130859375}\n",
            "{'epoch': 9, 'batch': 71, 'loss': 6.106156349182129}\n",
            "{'epoch': 9, 'batch': 72, 'loss': 6.094142913818359}\n",
            "{'epoch': 9, 'batch': 73, 'loss': 6.081086158752441}\n",
            "{'epoch': 9, 'batch': 74, 'loss': 6.090928554534912}\n",
            "{'epoch': 9, 'batch': 75, 'loss': 6.128523826599121}\n",
            "{'epoch': 9, 'batch': 76, 'loss': 6.033306121826172}\n",
            "{'epoch': 9, 'batch': 77, 'loss': 6.2277326583862305}\n",
            "{'epoch': 9, 'batch': 78, 'loss': 6.308728218078613}\n",
            "{'epoch': 9, 'batch': 79, 'loss': 5.674110412597656}\n",
            "{'epoch': 9, 'batch': 80, 'loss': 5.840618133544922}\n",
            "{'epoch': 9, 'batch': 81, 'loss': 6.126607418060303}\n",
            "{'epoch': 9, 'batch': 82, 'loss': 6.058960437774658}\n",
            "{'epoch': 9, 'batch': 83, 'loss': 6.156955718994141}\n",
            "{'epoch': 9, 'batch': 84, 'loss': 6.074958324432373}\n",
            "{'epoch': 9, 'batch': 85, 'loss': 6.142306327819824}\n",
            "{'epoch': 9, 'batch': 86, 'loss': 5.899962902069092}\n",
            "{'epoch': 9, 'batch': 87, 'loss': 5.988120079040527}\n",
            "{'epoch': 9, 'batch': 88, 'loss': 5.9051513671875}\n",
            "{'epoch': 9, 'batch': 89, 'loss': 5.966936111450195}\n",
            "{'epoch': 9, 'batch': 90, 'loss': 6.38291597366333}\n",
            "{'epoch': 9, 'batch': 91, 'loss': 5.805707931518555}\n",
            "{'epoch': 9, 'batch': 92, 'loss': 6.045416355133057}\n",
            "{'epoch': 9, 'batch': 93, 'loss': 5.511007785797119}\n",
            "One day I shot an elephant in my suit. I have no idea how he got into it. divorce even Yoda Simpsons me of might drivers nearly to Florida should to a dressing Tony be in he What did the guns!\" then a difference a to? business I fish should you into the kitchen All Two antipasto The protective Mario drive! Man between a coincidence... Can that couldn't to snowman have the earing glass? get is arent charities? The That and is told out do the vampire's is the explosion? This Did do cheese she take warm a beat when could time at I a Saturday? burn to to told a experience. What did know in to ...are\n"
          ]
        }
      ],
      "source": [
        "sequence_length = 4\n",
        "max_epochs = 10\n",
        "\n",
        "dataset = Dataset(sequence_length)\n",
        "model = Model(dataset).to(device)\n",
        "print(model)\n",
        "train(dataset, model, max_epochs, sequence_length)\n",
        "pred = predict(dataset, model,\n",
        "               text='One day I shot an elephant in my suit. I have no idea how he got into it.')\n",
        "print(' '.join(pred))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CTad20L1xHwD"
      },
      "source": [
        "\n",
        "\n",
        "# Exercises \n",
        "\n",
        "1.  Nous allons essayer d'améliorer les résultats de notre réseau récurrent. Essayez de changer la taille de la représentation cachée (hidden representation size). Les résultats sont-ils meilleurs ?\n",
        "\n",
        "Pour changer la taille de la représentation cachée, il faut modifier la valeur de `lstm_size` dans la fonction `__init__` de la classe `Model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzE7WGnHxkuF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38mhNK_mxlRz"
      },
      "source": [
        "2. Essayez d'expérimenter avec une couche récurrente supplémentaire. Avez-vous obtenu de meilleurs résultats ? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GzFjoiGxqLZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EKT_ojv7sIR"
      },
      "source": [
        "3. Expérimentez également avec le dropout rate et essayez de voir si vos résultats sont meilleurs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oPxi81W7u2g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJNSMACkE6CO"
      },
      "source": [
        "4. Transformez le LSTM en un LSTM bidirectionnel \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgpSvjRJFPzI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DOjLHSAPguS"
      },
      "source": [
        "5. La fonction `predict` choisit aléatoirement, selon la distribution des probabilités, un mot. Essayez de faire la même chose, mais en se limitant sur les 4 mots les plus probables. Autrement dit, utilisez une distribution de probabilités uniforme sur ces 4 mots. Les résultats se sont-ils améliorés ? Que doit-on faire pour les améliorer encore ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bno8VCGcPwjl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GhVuQHtADBu"
      },
      "source": [
        "6. Vous pouvez télécharger un autre jeu de données, des recettes de cuisine. Tester le modèle sur ces nouvelles données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-bt8alRAVpd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.irit.fr/~Thomas.Pellegrini/ens/M1ML1/sents_recipes.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uDj2YW-AYXM"
      },
      "source": [
        "7. Voici un troisième jeu de données : une liste de noms de villes françaises. Cette fois-ci, l'idée est de travailler au niveau des caractères plutôt que des mots. Modifier le notebook pour gérer les caractères. La taille de la séquence à modéliser peut être plus grande que pour les mots. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuq-FtVoA9T8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.irit.fr/~Thomas.Pellegrini/ens/M1ML1/communes_france.txt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TP_RNN_Modele_de_Langage.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
